{"config": {"lang": ["en"], "separator": "[\\s\\u200b\\u3000\\-\u3001\u3002\uff0c\uff0e\uff1f\uff01\uff1b]+", "pipeline": ["stemmer"], "fields": {"title": {"boost": 1000.0}, "text": {"boost": 1.0}, "tags": {"boost": 1000000.0}}}, "docs": [{"location": "", "title": "\u6b22\u8fce\u6765\u5230\u6211\u7684\u5b66\u4e60\u7a7a\u95f4", "text": "<p>\u8fd9\u91cc\u662f\u6211\u8bb0\u5f55 Python \u5b66\u4e60\u548c\u6280\u672f\u63a2\u7d22\u7684\u5730\u65b9\u3002</p>"}, {"location": "#_2", "title": "\u4eca\u65e5\u76ee\u6807", "text": "<p>\u8fd9\u662f\u4e8c\u7ea7\u6807\u9898\uff0c\u7528\u6765\u7ed9\u6587\u7ae0\u5206\u6bb5\u3002</p> <ul> <li> \u642d\u5efa\u535a\u5ba2\u73af\u5883</li> <li> \u5b66\u4e60 Markdown \u8bed\u6cd5</li> <li> \u5199\u4e0b\u7b2c\u4e00\u884c Python \u4ee3\u7801</li> </ul>"}, {"location": "#_3", "title": "\u6211\u7684\u7b2c\u4e00\u6bb5\u4ee3\u7801", "text": "<p>Markdown \u6700\u5f3a\u5927\u7684\u5730\u65b9\u5c31\u662f\u53ef\u4ee5\u9ad8\u4eae\u4ee3\u7801\uff0c\u770b\u4e0b\u9762\uff1a</p> <pre><code># \u8fd9\u662f\u4e00\u4e2a\u4ee3\u7801\u5757\uff0c\u7528\u4e09\u4e2a\u53cd\u5f15\u53f7\u5305\u88f9\ndef hello_blog():\n    print(\"Hello, World!\")\n\nhello_blog()\n</code></pre>"}, {"location": "build_blog/", "title": "\u6211\u662f\u5982\u4f55\u7528 Python \u642d\u5efa\u4e2a\u4eba\u535a\u5ba2\u7684", "text": "<p>\u8fd9\u662f\u6211\u535a\u5ba2\u7684\u7b2c\u4e00\u7bc7\u6b63\u5f0f\u6280\u672f\u6587\u7ae0\u3002\u5728\u8fd9\u7bc7\u6587\u7ae0\u91cc\uff0c\u6211\u60f3\u5206\u4eab\u6211\u662f\u5982\u4f55\u5229\u7528 Python \u548c\u5f00\u6e90\u5de5\u5177\uff0c\u5728\u96f6\u6210\u672c\u7684\u60c5\u51b5\u4e0b\u642d\u5efa\u8d77\u8fd9\u4e2a\u72ec\u7acb\u535a\u5ba2\u7684\u3002</p>"}, {"location": "build_blog/#_1", "title": "\u4e3a\u4ec0\u4e48\u9009\u62e9\u201c\u6298\u817e\u201d\uff1f", "text": "<p>\u5176\u5b9e\u73b0\u5728\u7684\u5199\u4f5c\u5e73\u53f0\u5f88\u591a\uff08\u77e5\u4e4e\u3001\u516c\u4f17\u53f7\u7b49\uff09\uff0c\u4f46\u6211\u4f9d\u7136\u9009\u62e9\u81ea\u5df1\u642d\u5efa\u4e00\u4e2a\u535a\u5ba2\uff0c\u539f\u56e0\u5f88\u7b80\u5355\uff1a</p> <ol> <li>\u6570\u636e\u81ea\u4e3b\uff1a\u6240\u6709\u7684\u6587\u7ae0\u6e90\u7801\u90fd\u4fdd\u5b58\u5728\u6211\u81ea\u5df1\u7684 GitHub \u4ed3\u5e93\u91cc\uff0c\u4e0d\u4f1a\u56e0\u4e3a\u5e73\u53f0\u89c4\u5219\u53d8\u52a8\u800c\u4e22\u5931\u3002</li> <li>\u6781\u5ba2\u7cbe\u795e\uff1a\u4f5c\u4e3a\u4e00\u540d\u7f16\u7a0b\u5b66\u4e60\u8005\uff0c\u7528\u4ee3\u7801\u6784\u5efa\u81ea\u5df1\u7684\u201c\u540e\u82b1\u56ed\u201d\u672c\u8eab\u5c31\u662f\u4e00\u4ef6\u5f88\u6709\u6210\u5c31\u611f\u7684\u4e8b\u3002</li> <li>\u6280\u672f\u79ef\u7d2f\uff1a\u5728\u642d\u5efa\u8fc7\u7a0b\u4e2d\uff0c\u6211\u987a\u4fbf\u719f\u6089\u4e86 Python \u73af\u5883\u3001\u547d\u4ee4\u884c\u64cd\u4f5c\u548c Git \u7248\u672c\u63a7\u5236\u3002</li> </ol>"}, {"location": "build_blog/#_2", "title": "\u6211\u7684\u6280\u672f\u6808", "text": "<p>\u6211\u7684\u535a\u5ba2\u5e76\u4e0d\u662f\u4ece\u96f6\u5f00\u59cb\u5199 HTML/CSS\uff0c\u800c\u662f\u7ad9\u5728\u4e86\u5de8\u4eba\u7684\u80a9\u8180\u4e0a\u3002\u4ee5\u4e0b\u662f\u6211\u4f7f\u7528\u7684\u6838\u5fc3\u5de5\u5177\uff1a</p> \u5de5\u5177 \u4f5c\u7528 \u5907\u6ce8 Python \u57fa\u7840\u8bed\u8a00\u73af\u5883 \u5f3a\u5927\u7684\u751f\u6001\u652f\u6301 MkDocs \u9759\u6001\u7f51\u7ad9\u751f\u6210\u5668 \u628a Markdown \u8f6c\u6362\u6210\u7f51\u9875\u7684\u5f15\u64ce Material \u4e3b\u9898\u76ae\u80a4 \u63d0\u4f9b\u7f8e\u89c2\u7684 UI \u548c\u54cd\u5e94\u5f0f\u8bbe\u8ba1 GitHub Pages \u7f51\u7ad9\u6258\u7ba1 \u514d\u8d39\u7684\u4e91\u7aef\u670d\u52a1\u5668 PyCharm \u6211\u7684\u5f00\u53d1\u795e\u5668 \u7f16\u5199\u548c\u7ba1\u7406\u4ee3\u7801\u7684\u5730\u65b9"}, {"location": "build_blog/#_3", "title": "\u642d\u5efa\u8fc7\u7a0b\u590d\u76d8", "text": "<p>\u6574\u4e2a\u8fc7\u7a0b\u6bd4\u6211\u60f3\u8c61\u4e2d\u8981\u7b80\u5355\uff0c\u6838\u5fc3\u53ea\u6709\u4e09\u6b65\uff1a</p>"}, {"location": "build_blog/#1", "title": "1. \u5b89\u88c5\u201c\u5f15\u64ce\u201d", "text": "<p>\u5229\u7528 Python \u7684\u5305\u7ba1\u7406\u5de5\u5177 pip\uff0c\u5b89\u88c5 MkDocs \u548c Material \u4e3b\u9898\uff1a</p> <pre><code>pip install mkdocs-material\n</code></pre>"}, {"location": "build_blog/#2", "title": "2. \u521d\u59cb\u5316\u9879\u76ee", "text": "<p>\u4e00\u884c\u547d\u4ee4\u751f\u6210\u535a\u5ba2\u7684\u57fa\u7840\u9aa8\u67b6\uff1a</p> <pre><code>mkdocs new .\n</code></pre>"}, {"location": "build_blog/#3", "title": "3. \u914d\u7f6e\u4e0e\u53d1\u5e03", "text": "<p>\u5728 <code>mkdocs.yml</code> \u4e2d\u914d\u7f6e\u597d\u7f51\u7ad9\u540d\u79f0\u548c\u4e3b\u9898\u540e\uff0c\u4f7f\u7528 MkDocs \u63d0\u4f9b\u7684\u547d\u4ee4\u4e00\u952e\u90e8\u7f72\u5230 GitHub\uff1a</p> <pre><code>mkdocs gh-deploy\n</code></pre> <p>\u5c31\u662f\u8fd9\u4e48\u7b80\u5355\uff01\u5269\u4e0b\u7684\u5de5\u4f5c\uff0c\u5c31\u662f\u4e13\u6ce8\u4e8e\u7528 Markdown \u5199\u4f5c\u4e86\u3002</p>"}, {"location": "build_blog/#_4", "title": "\u9047\u5230\u7684\u5751\u4e0e\u89e3\u51b3", "text": "<p>\u5728\u642d\u5efa\u8fc7\u7a0b\u4e2d\uff0c\u6211\u4e5f\u9047\u5230\u4e86\u4e00\u4e9b\u5c0f\u63d2\u66f2\uff08\u6bd4\u5982 Markdown \u4ee3\u7801\u5757\u7684\u8bed\u6cd5\u95ee\u9898\uff09\uff0c\u4f46\u901a\u8fc7\u67e5\u9605\u6587\u6863\u548c\u8c03\u8bd5\uff0c\u6700\u7ec8\u90fd\u89e3\u51b3\u4e86\u3002\u8fd9\u4e5f\u8ba9\u6211\u660e\u767d\uff1a\u7f16\u7a0b\u4e0d\u4ec5\u4ec5\u662f\u5199\u4ee3\u7801\uff0c\u66f4\u662f\u89e3\u51b3\u95ee\u9898\u7684\u8fc7\u7a0b\u3002</p>"}, {"location": "build_blog/#_5", "title": "\u5199\u5728\u6700\u540e", "text": "<p>\u8fd9\u4e2a\u535a\u5ba2\u76ee\u524d\u8fd8\u5f88\u7b80\u6d01\uff0c\u672a\u6765\u6211\u8ba1\u5212\uff1a</p> <ul> <li> \u8bb0\u5f55\u6211\u7684 C \u8bed\u8a00\u548c Python \u5b66\u4e60\u7b14\u8bb0</li> <li> \u5c1d\u8bd5\u4fee\u6539\u535a\u5ba2\u7684\u6837\u5f0f\uff08CSS\uff09</li> <li> \u575a\u6301\u6bcf\u5468\u66f4\u65b0</li> </ul> <p>\u5982\u679c\u4f60\u4e5f\u5bf9\u642d\u5efa\u535a\u5ba2\u611f\u5174\u8da3\uff0c\u6b22\u8fce\u4e0e\u6211\u4ea4\u6d41\uff01</p>"}, {"location": "guide/", "title": "\u535a\u5ba2\u65e5\u5e38\u7ef4\u62a4\u624b\u518c", "text": "<p>\u8fd9\u662f\u6211\u7684\u535a\u5ba2\u7ba1\u7406\u5907\u5fd8\u5f55\u3002\u4ee5\u540e\u6bcf\u6b21\u66f4\u65b0\u6587\u7ae0\uff0c\u6309\u7167\u8fd9\u4e2a\u6d41\u7a0b\u64cd\u4f5c\u5373\u53ef\u3002</p>"}, {"location": "guide/#4", "title": "\u4e00\u3001 \u65e5\u5e38\u66f4\u65b0\u6d41\u7a0b (4\u6b65\u6cd5)", "text": ""}, {"location": "guide/#1-write", "title": "\u7b2c 1 \u6b65\uff1a\u521b\u4f5c (Write)", "text": "<p>\u5728 <code>docs</code> \u6587\u4ef6\u5939\u4e0b\u65b0\u5efa <code>.md</code> \u6587\u4ef6\uff0c\u4f7f\u7528 Markdown \u8bed\u6cd5\u7f16\u5199\u5185\u5bb9\u3002</p>"}, {"location": "guide/#2-preview", "title": "\u7b2c 2 \u6b65\uff1a\u9884\u89c8 (Preview)", "text": "<p>\u5728 PyCharm \u7684 Terminal \u4e2d\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\uff0c\u542f\u52a8\u672c\u5730\u670d\u52a1\u5668\uff1a</p> <pre><code>mkdocs serve\n</code></pre> <ul> <li>\u6253\u5f00\u6d4f\u89c8\u5668\u8bbf\u95ee\uff1a[http://127.0.0.1:8000]</li> <li>\u68c0\u67e5\u6392\u7248\u548c\u5185\u5bb9\uff0c\u786e\u8ba4\u65e0\u8bef\u540e\u6309 <code>Ctrl + C</code> \u505c\u6b62\u670d\u52a1\u3002</li> </ul>"}, {"location": "guide/#3-deploy", "title": "\u7b2c 3 \u6b65\uff1a\u53d1\u5e03 (Deploy)", "text": "<p>\u5c06\u751f\u6210\u7684\u9759\u6001\u7f51\u9875\u63a8\u9001\u5230 GitHub Pages\uff0c\u8ba9\u7f51\u7ad9\u4e0a\u7ebf\uff1a</p> <pre><code>mkdocs gh-deploy\n</code></pre>"}, {"location": "guide/#4-backup", "title": "\u7b2c 4 \u6b65\uff1a\u5907\u4efd\u6e90\u7801 (Backup)", "text": "<p>\u91cd\u8981\uff01 \u8fd9\u4e00\u6b65\u662f\u4e3a\u4e86\u9632\u6b62\u6e90\u7801\u4e22\u5931\u3002\u5c06\u672c\u5730\u7684 Markdown \u539f\u7a3f\u540c\u6b65\u5230 GitHub \u4ed3\u5e93\uff1a</p> <pre><code>git add .\ngit commit -m \"\u65e5\u5e38\u66f4\u65b0\uff1a\u65b0\u589e\u6587\u7ae0\"\ngit push\n</code></pre>"}, {"location": "guide/#_2", "title": "\u4e8c\u3001 \u8fdb\u9636\u914d\u7f6e\uff1a\u7ba1\u7406\u83dc\u5355\u680f", "text": "<p>\u5982\u679c\u8981\u8c03\u6574\u6587\u7ae0\u5728\u5de6\u4fa7\u5bfc\u822a\u680f\u7684\u987a\u5e8f\uff0c\u9700\u8981\u4fee\u6539\u6839\u76ee\u5f55\u4e0b\u7684 <code>mkdocs.yml</code> \u6587\u4ef6\u3002</p> <p>\u627e\u5230 <code>nav</code> \u914d\u7f6e\u9879\uff08\u5982\u679c\u6ca1\u6709\u5c31\u81ea\u5df1\u52a0\u4e0a\uff09\uff1a</p> <pre><code>site_name: \u6211\u7684 Python \u5b66\u4e60\u7b14\u8bb0\ntheme:\n  name: material\n\n# \u5bfc\u822a\u680f\u914d\u7f6e\nnav:\n  - \u9996\u9875: index.md\n  - \u535a\u5ba2\u6307\u5357: guide.md  # &lt;--- \u8fd9\u5c31\u662f\u6211\u73b0\u5728\u8fd9\u7bc7\u6587\u7ae0\n  - Python\u7b14\u8bb0:\n      - \u53d8\u91cf\u4e0e\u7c7b\u578b: python_basic.md\n  - \u968f\u60f3: thoughts.md\n</code></pre> <p>\u6ce8\u610f\uff1a\u4fee\u6539 <code>mkdocs.yml</code> \u4e4b\u540e\uff0c\u901a\u5e38\u9700\u8981\u91cd\u542f <code>mkdocs serve</code> \u624d\u80fd\u770b\u5230\u6548\u679c\u3002</p>"}, {"location": "cv/Image_Classification/", "title": "\u56fe\u50cf\u5206\u7c7b\u6a21\u578b\u901a\u7528\u6a21\u677f", "text": "<p>\u6458\u8981\uff1a\u4e00\u4e2a\u53ef\u914d\u7f6e\u7684\u4ee3\u7801\u6a21\u677f\uff0c\u7528\u4e8e\u8bad\u7ec3\u56fe\u50cf\u5206\u7c7b\u6a21\u578b</p>", "tags": ["Python", "\u8ba1\u7b97\u673a\u89c6\u89c9", "\u56fe\u50cf\u5206\u7c7b"]}, {"location": "cv/Image_Classification/#_2", "title": "\u6838\u5fc3\u4ee3\u7801\uff1a", "text": "<pre><code>import os\nimport sys\nimport time\nimport random\nimport logging\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import datasets, transforms\nimport timm\nfrom timm.data import resolve_data_config\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\n# \u68c0\u67e5\u9ad8\u7ea7\u7ed8\u56fe\u5e93\ntry:\n    from sklearn.metrics import classification_report, confusion_matrix\n    import seaborn as sns\n    HAS_SKLEARN = True\nexcept ImportError:\n    HAS_SKLEARN = False\n    print(\"[Warning] \u672a\u5b89\u88c5 sklearn \u6216 seaborn\uff0c\u8df3\u8fc7\u6df7\u6dc6\u77e9\u9635\u7ed8\u5236\u3002\")\n\n# ==========================================\n# 1. \u5168\u5c40\u914d\u7f6e [\u6838\u5fc3\u4fee\u6539\u533a]\n# ==========================================\nclass Config:\n    # --- \u6570\u636e\u96c6\u8bbe\u7f6e ---\n    USE_CUSTOM_DATASET = True        # &lt;--- [\u53ef\u5fae\u8c03] True=\u81ea\u5b9a\u4e49\u6587\u4ef6\u5939, False=\u5185\u7f6e\n    CUSTOM_DATA_ROOT = \"flower_data\" # &lt;--- [\u53ef\u5fae\u8c03] \u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u8def\u5f84\n    BUILTIN_NAME = \"CIFAR10\"         # &lt;--- [\u53ef\u5fae\u8c03] \u5185\u7f6e\u6570\u636e\u96c6\u540d\u79f0\n    DATA_DOWNLOAD_ROOT = \"./data\"    # &lt;--- [\u53ef\u5fae\u8c03] \u4e0b\u8f7d\u7f13\u5b58\u8def\u5f84\n\n    # --- \u7ed3\u679c\u4fdd\u5b58 ---\n    SAVE_DIR_ROOT = \"./results\"      # &lt;--- [\u53ef\u5fae\u8c03] \u7ed3\u679c\u4fdd\u5b58\u6839\u76ee\u5f55\n    SAVE_DIR = \"\"                    # (\u8fd0\u884c\u65f6\u81ea\u52a8\u751f\u6210)\n\n    # --- \u6a21\u578b\u8bbe\u7f6e ---\n    MODEL_NAME = \"resnet50\"          # &lt;--- [\u53ef\u5fae\u8c03] \u6a21\u578b\u540d\u79f0 (timm\u5e93\u652f\u6301\u7684\u540d\u79f0)\n    CHECKPOINT_PATH = \"\"             # &lt;--- [\u53ef\u5fae\u8c03] \u521d\u59cb\u9884\u8bad\u7ec3\u6743\u91cd (\u8fc1\u79fb\u5b66\u4e60\u7528)\n    RESUME_PATH = \"\"                 # &lt;--- [\u53ef\u5fae\u8c03] \u65ad\u70b9\u7eed\u8bad\u6587\u4ef6\u8def\u5f84 (.pth)\n    NUM_CLASSES = 0                  # (\u8fd0\u884c\u65f6\u81ea\u52a8\u8986\u76d6)\n\n    # --- \u8bad\u7ec3\u8d85\u53c2\u6570 ---\n    BATCH_SIZE = 32                  # &lt;--- [\u53ef\u5fae\u8c03] \u6279\u6b21\u5927\u5c0f\n    EPOCHS = 50                      # &lt;--- [\u53ef\u5fae\u8c03] \u8bad\u7ec3\u603b\u8f6e\u6570\n    LR = 1e-4                        # &lt;--- [\u53ef\u5fae\u8c03] \u521d\u59cb\u5b66\u4e60\u7387\n    WEIGHT_DECAY = 1e-4              # &lt;--- [\u53ef\u5fae\u8c03] L2\u6b63\u5219\u5316\u7cfb\u6570\n    SEED = 42                        # &lt;--- [\u53ef\u5fae\u8c03] \u968f\u673a\u79cd\u5b50\n\n    # --- \u7b56\u7565\u9009\u62e9 ---\n    OPTIMIZER_NAME = 'adamw'         # &lt;--- [\u53ef\u5fae\u8c03] 'adamw', 'adam', 'sgd'\n    SCHEDULER_NAME = 'plateau'       # &lt;--- [\u53ef\u5fae\u8c03] 'plateau', 'cosine', 'step'\n    EARLY_STOP_PATIENCE = 7          # &lt;--- [\u53ef\u5fae\u8c03] \u65e9\u505c\u8010\u5fc3\u8f6e\u6570 (0=\u5173\u95ed)\n\n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# ==========================================\n# 2. \u8f85\u52a9\u5de5\u5177\n# ==========================================\ndef setup_logger(save_dir):\n    \"\"\"\u914d\u7f6e\u65e5\u5fd7\uff1a\u540c\u65f6\u8f93\u51fa\u5230\u6587\u4ef6\u548c\u63a7\u5236\u53f0\"\"\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format='%(asctime)s - %(message)s',\n        handlers=[\n            logging.FileHandler(os.path.join(save_dir, \"train.log\")),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    return logging.getLogger()\n\ndef seed_everything(seed):\n    \"\"\"\u56fa\u5b9a\u968f\u673a\u79cd\u5b50\"\"\"\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nclass EarlyStopping:\n    \"\"\"\u65e9\u505c\u63a7\u5236\u5668\"\"\"\n    def __init__(self, patience=7, delta=0):\n        self.patience = patience\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.delta = delta\n\n    def __call__(self, val_acc):\n        if self.patience &lt;= 0: return\n        if self.best_score is None:\n            self.best_score = val_acc\n        elif val_acc &lt; self.best_score + self.delta:\n            self.counter += 1\n            if self.counter &gt;= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = val_acc\n            self.counter = 0\n\ndef get_optimizer(model):\n    \"\"\"\u4f18\u5316\u5668\u5de5\u5382\"\"\"\n    name = Config.OPTIMIZER_NAME.lower()\n    p = model.parameters()\n    if name == 'adamw': return optim.AdamW(p, lr=Config.LR, weight_decay=Config.WEIGHT_DECAY)\n    elif name == 'sgd': return optim.SGD(p, lr=Config.LR, momentum=0.9, weight_decay=Config.WEIGHT_DECAY)\n    else: return optim.Adam(p, lr=Config.LR, weight_decay=Config.WEIGHT_DECAY)\n\ndef get_scheduler(optimizer):\n    \"\"\"\u5b66\u4e60\u7387\u7b56\u7565\u5de5\u5382\"\"\"\n    name = Config.SCHEDULER_NAME.lower()\n    if name == 'plateau': return optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)\n    elif name == 'cosine': return optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=Config.EPOCHS, eta_min=1e-6)\n    elif name == 'step': return optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n    return None\n\n# ==========================================\n# 3. \u6570\u636e\u52a0\u8f7d\u4e0e\u5904\u7406\n# ==========================================\ndef get_transforms(model_cfg):\n    \"\"\"\u6839\u636e\u6a21\u578b\u914d\u7f6e\u751f\u6210Transforms\"\"\"\n    input_size = model_cfg.get('input_size', (3, 224, 224))\n    crop_size = input_size[1]\n    mean = model_cfg.get('mean', [0.485, 0.456, 0.406])\n    std = model_cfg.get('std', [0.229, 0.224, 0.225])\n\n    train_tf = transforms.Compose([\n        transforms.Resize((crop_size, crop_size)),\n        transforms.RandomHorizontalFlip(0.5),\n        transforms.RandomRotation(15),\n        transforms.ColorJitter(0.1, 0.1, 0.1),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ])\n    val_tf = transforms.Compose([\n        transforms.Resize((crop_size, crop_size)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ])\n    return train_tf, val_tf\n\ndef get_dataloaders(train_tf, val_tf, logger):\n    \"\"\"\u52a0\u8f7d\u6570\u636e\u96c6\"\"\"\n    if not Config.USE_CUSTOM_DATASET:\n        logger.info(f\"[Data] \u52a0\u8f7d\u5185\u7f6e\u6570\u636e\u96c6: {Config.BUILTIN_NAME}\")\n        try: DatasetClass = getattr(datasets, Config.BUILTIN_NAME)\n        except AttributeError: raise ValueError(f\"\u4e0d\u652f\u6301\u7684\u6570\u636e\u96c6: {Config.BUILTIN_NAME}\")\n\n        full_ds = DatasetClass(root=Config.DATA_DOWNLOAD_ROOT, train=True, download=True, transform=train_tf)\n        test_ds = DatasetClass(root=Config.DATA_DOWNLOAD_ROOT, train=False, download=True, transform=val_tf)\n\n        train_sz = int(0.9 * len(full_ds))\n        train_ds, val_ds = random_split(full_ds, [train_sz, len(full_ds)-train_sz])\n        class_names = full_ds.classes\n        ds_name = Config.BUILTIN_NAME\n    else:\n        logger.info(f\"[Data] \u52a0\u8f7d\u81ea\u5b9a\u4e49\u6587\u4ef6\u5939: {Config.CUSTOM_DATA_ROOT}\")\n        train_dir = os.path.join(Config.CUSTOM_DATA_ROOT, \"train\")\n        val_dir = os.path.join(Config.CUSTOM_DATA_ROOT, \"val\")\n        test_dir = os.path.join(Config.CUSTOM_DATA_ROOT, \"test\")\n\n        if not os.path.exists(train_dir): raise FileNotFoundError(f\"\u7f3a\u5931\u76ee\u5f55: {train_dir}\")\n        train_ds = datasets.ImageFolder(train_dir, transform=train_tf)\n        val_ds = datasets.ImageFolder(val_dir, transform=val_tf)\n        test_ds = datasets.ImageFolder(test_dir, transform=val_tf) if os.path.exists(test_dir) else None\n        class_names = train_ds.classes\n        ds_name = os.path.basename(Config.CUSTOM_DATA_ROOT)\n\n    Config.NUM_CLASSES = len(class_names)\n    logger.info(f\"[Data] \u7c7b\u522b\u6570: {Config.NUM_CLASSES}\")\n\n    train_dl = DataLoader(train_ds, batch_size=Config.BATCH_SIZE, shuffle=True, num_workers=4)\n    val_dl = DataLoader(val_ds, batch_size=Config.BATCH_SIZE, shuffle=False, num_workers=4)\n    test_dl = DataLoader(test_ds, batch_size=Config.BATCH_SIZE, shuffle=False, num_workers=4) if test_ds else None\n\n    return train_dl, val_dl, test_dl, class_names, ds_name\n\n# ==========================================\n# 4. \u8bad\u7ec3\u4e0e\u9a8c\u8bc1\u6838\u5fc3\n# ==========================================\ndef train_one_epoch(model, loader, criterion, optimizer, epoch):\n    model.train()\n    total_loss, total_correct = 0.0, 0\n    bar = tqdm(loader, desc=f\"Epoch {epoch}/{Config.EPOCHS} [Train]\", leave=False)\n\n    for imgs, labels in bar:\n        imgs, labels = imgs.to(Config.DEVICE), labels.to(Config.DEVICE)\n\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item() * imgs.size(0)\n        total_correct += (outputs.argmax(1) == labels).sum().item()\n        bar.set_postfix(loss=loss.item(), lr=optimizer.param_groups[0]['lr'])\n\n    return total_loss / len(loader.dataset), total_correct / len(loader.dataset)\n\n@torch.no_grad()\ndef validate(model, loader, criterion, epoch, phase=\"Val\"):\n    model.eval()\n    total_loss, total_correct = 0.0, 0\n    bar = tqdm(loader, desc=f\"Epoch {epoch}/{Config.EPOCHS} [{phase}]  \", leave=False)\n\n    for imgs, labels in bar:\n        imgs, labels = imgs.to(Config.DEVICE), labels.to(Config.DEVICE)\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n\n        total_loss += loss.item() * imgs.size(0)\n        total_correct += (outputs.argmax(1) == labels).sum().item()\n        bar.set_postfix(loss=loss.item())\n\n    return total_loss / len(loader.dataset), total_correct / len(loader.dataset)\n\ndef evaluate_test_set(model, loader, class_names, logger):\n    \"\"\"\u6d4b\u8bd5\u96c6\u8bc4\u4f30\u4e0e\u6df7\u6dc6\u77e9\u9635\u7ed8\u5236\"\"\"\n    if not loader or not HAS_SKLEARN: return\n    logger.info(\"[Test] \u6267\u884c\u6700\u7ec8\u8bc4\u4f30...\")\n    model.eval()\n    preds, targets = [], []\n\n    with torch.no_grad():\n        for imgs, labels in tqdm(loader, desc=\"Testing\"):\n            imgs, labels = imgs.to(Config.DEVICE), labels.to(Config.DEVICE)\n            outputs = model(imgs)\n            preds.extend(outputs.argmax(1).cpu().numpy())\n            targets.extend(labels.cpu().numpy())\n\n    report = classification_report(targets, preds, target_names=class_names, digits=4)\n    logger.info(\"\\n\" + report)\n    print(report)\n\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(confusion_matrix(targets, preds), annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n    plt.title('Confusion Matrix'); plt.savefig(os.path.join(Config.SAVE_DIR, 'confusion_matrix.png'))\n    logger.info(\"[Info] \u6df7\u6dc6\u77e9\u9635\u5df2\u4fdd\u5b58\")\n\ndef plot_history(h, save_dir, logger):\n    epochs = range(1, len(h['train_acc']) + 1)\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1); plt.plot(epochs, h['train_acc'], label='Train'); plt.plot(epochs, h['val_acc'], label='Val'); plt.legend(); plt.title('Accuracy')\n    plt.subplot(1, 2, 2); plt.plot(epochs, h['train_loss'], label='Train'); plt.plot(epochs, h['val_loss'], label='Val'); plt.legend(); plt.title('Loss')\n    plt.savefig(os.path.join(save_dir, 'training_curve.png'))\n    logger.info(\"[Info] \u8bad\u7ec3\u66f2\u7ebf\u5df2\u4fdd\u5b58\")\n\ndef save_checkpoint(state, is_best, filename='last.pth'):\n    path = os.path.join(Config.SAVE_DIR, filename)\n    torch.save(state, path)\n    if is_best: torch.save(state, os.path.join(Config.SAVE_DIR, 'best_model.pth'))\n\n# ==========================================\n# 5. \u4e3b\u7a0b\u5e8f\n# ==========================================\nif __name__ == \"__main__\":\n    seed_everything(Config.SEED)\n\n    # 1. \u786e\u5b9a\u4fdd\u5b58\u76ee\u5f55\n    if Config.RESUME_PATH:\n        # \u65ad\u70b9\u7eed\u8bad\u590d\u7528\u539f\u76ee\u5f55\n        Config.SAVE_DIR = os.path.dirname(Config.RESUME_PATH)\n    else:\n        # \u83b7\u53d6\u6570\u636e\u96c6\u540d\u79f0\u7528\u4e8e\u547d\u540d\n        if Config.USE_CUSTOM_DATASET:\n            ds_name = os.path.basename(Config.CUSTOM_DATA_ROOT)\n        else:\n            ds_name = Config.BUILTIN_NAME\n\n        # \u683c\u5f0f: \u6a21\u578b\u540d_\u6570\u636e\u96c6\u540d_\u65f6\u95f4\u6233\n        run_name = f\"{Config.MODEL_NAME}_{ds_name}_{time.strftime('%Y%m%d_%H%M%S')}\"\n        Config.SAVE_DIR = os.path.join(Config.SAVE_DIR_ROOT, run_name)\n        os.makedirs(Config.SAVE_DIR, exist_ok=True)\n\n    logger = setup_logger(Config.SAVE_DIR)\n    logger.info(f\"[Config] \u4fdd\u5b58\u76ee\u5f55: {Config.SAVE_DIR}\")\n\n    # 2. \u51c6\u5907\u6570\u636e\n    tmp_model = timm.create_model(Config.MODEL_NAME, pretrained=True)\n    cfg = resolve_data_config({}, model=tmp_model)\n    del tmp_model\n\n    train_tf, val_tf = get_transforms(cfg)\n    train_dl, val_dl, test_dl, class_names, ds_name = get_dataloaders(train_tf, val_tf, logger)\n\n    # 3. \u521d\u59cb\u5316\u6a21\u578b\n    logger.info(f\"[Init] \u521b\u5efa\u6a21\u578b: {Config.MODEL_NAME}\")\n    if not Config.RESUME_PATH and Config.CHECKPOINT_PATH and os.path.exists(Config.CHECKPOINT_PATH):\n        logger.info(f\"[Load] \u52a0\u8f7d\u672c\u5730\u521d\u59cb\u5316\u6743\u91cd: {Config.CHECKPOINT_PATH}\")\n        model = timm.create_model(Config.MODEL_NAME, pretrained=False, checkpoint_path=Config.CHECKPOINT_PATH)\n    else:\n        model = timm.create_model(Config.MODEL_NAME, pretrained=True)\n\n    model.reset_classifier(num_classes=Config.NUM_CLASSES)\n    model.to(Config.DEVICE)\n\n    # 4. \u4f18\u5316\u5668/\u8c03\u5ea6\u5668/Loss\n    optimizer = get_optimizer(model)\n    scheduler = get_scheduler(optimizer)\n    criterion = nn.CrossEntropyLoss()\n    early_stop = EarlyStopping(patience=Config.EARLY_STOP_PATIENCE) if Config.EARLY_STOP_PATIENCE &gt; 0 else None\n\n    # 5. \u65ad\u70b9\u6062\u590d\u903b\u8f91\n    start_epoch = 1\n    best_acc = 0.0\n    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n\n    if Config.RESUME_PATH and os.path.exists(Config.RESUME_PATH):\n        logger.info(f\"[Resume] \u6062\u590d\u65ad\u70b9: {Config.RESUME_PATH}\")\n        ckpt = torch.load(Config.RESUME_PATH, map_location=Config.DEVICE)\n        model.load_state_dict(ckpt['state_dict'])\n        optimizer.load_state_dict(ckpt['optimizer'])\n        if scheduler and 'scheduler' in ckpt: scheduler.load_state_dict(ckpt['scheduler'])\n\n        start_epoch = ckpt['epoch'] + 1\n        best_acc = ckpt['best_acc']\n        history = ckpt['history']\n        logger.info(f\"[Resume] \u4ece\u7b2c {start_epoch} \u8f6e\u7ee7\u7eed (\u6700\u4f73Acc: {best_acc:.4f})\")\n\n    # 6. \u8bad\u7ec3\u5faa\u73af\n    logger.info(\"[Start] \u5f00\u59cb\u8bad\u7ec3...\")\n    for epoch in range(start_epoch, Config.EPOCHS + 1):\n        t_loss, t_acc = train_one_epoch(model, train_dl, criterion, optimizer, epoch)\n        v_loss, v_acc = validate(model, val_dl, criterion, epoch)\n\n        history['train_loss'].append(t_loss); history['train_acc'].append(t_acc)\n        history['val_loss'].append(v_loss); history['val_acc'].append(v_acc)\n\n        logger.info(f\"Epoch {epoch}: Train Acc: {t_acc:.4f} | Val Acc: {v_acc:.4f} | Loss: {t_loss:.4f}\")\n\n        # \u5b66\u4e60\u7387\u66f4\u65b0\n        if scheduler:\n            if Config.SCHEDULER_NAME == 'plateau': scheduler.step(v_acc)\n            else: scheduler.step()\n\n        # \u4fdd\u5b58\u6700\u4f73\u6a21\u578b\n        is_best = v_acc &gt; best_acc\n        if is_best:\n            best_acc = v_acc\n            logger.info(f\" -&gt; \ud83c\udf1f \u65b0\u7684\u6700\u4f73\u6a21\u578b (Acc: {best_acc:.4f})\")\n\n        # \u4fdd\u5b58\u65ad\u70b9\n        save_checkpoint({\n            'epoch': epoch,\n            'state_dict': model.state_dict(),\n            'best_acc': best_acc,\n            'optimizer': optimizer.state_dict(),\n            'scheduler': scheduler.state_dict() if scheduler else None,\n            'history': history\n        }, is_best)\n\n        # \u65e9\u505c\u68c0\u6d4b\n        if early_stop:\n            early_stop(v_acc)\n            if early_stop.early_stop:\n                logger.info(\"[Stop] \u89e6\u53d1\u65e9\u505c\")\n                break\n\n    # 7. \u6536\u5c3e\n    plot_history(history, Config.SAVE_DIR, logger)\n    if test_dl:\n        ckpt = torch.load(os.path.join(Config.SAVE_DIR, \"best_model.pth\"), map_location=Config.DEVICE)\n        model.load_state_dict(ckpt['state_dict'])\n        evaluate_test_set(model, test_dl, class_names, logger)\n\n    logger.info(\"[Done] \u5b8c\u6210\")\n</code></pre>", "tags": ["Python", "\u8ba1\u7b97\u673a\u89c6\u89c9", "\u56fe\u50cf\u5206\u7c7b"]}, {"location": "cv/Predict_img/", "title": "\u5bf9\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u8fdb\u884c\u5355\u5f20\u56fe\u7247\u9884\u6d4b", "text": "", "tags": ["Python", "\u8ba1\u7b97\u673a\u89c6\u89c9", "\u56fe\u50cf\u5206\u7c7b"]}, {"location": "cv/Predict_img/#_2", "title": "\u6838\u5fc3\u4ee3\u7801\uff1a", "text": "<pre><code>import os\nimport torch\nimport timm\nfrom timm.data import resolve_data_config\nfrom torchvision import transforms\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\n\n\n# ==========================================\n# 1. \u914d\u7f6e\u533a\u57df [\u6838\u5fc3\u4fee\u6539\u533a]\n# ==========================================\nclass Config:\n    # --- \u6a21\u578b\u4e0e\u6743\u91cd ---\n    MODEL_NAME = \"resnet50\"  # &lt;--- [\u5fc5\u987b\u4fee\u6539] \u9700\u4e0e\u8bad\u7ec3\u65f6\u4e00\u81f4\n    NUM_CLASSES = 5  # &lt;--- [\u5fc5\u987b\u4fee\u6539] \u7c7b\u522b\u6570 (\u5fc5\u987b\u4e0e\u8bad\u7ec3\u65f6\u4e00\u81f4)\n    WEIGHT_PATH = \"./results/xxx/best_model.pth\"  # &lt;--- [\u5fc5\u987b\u4fee\u6539] \u8bad\u7ec3\u597d\u7684\u6743\u91cd\u8def\u5f84\n\n    # --- \u8f93\u5165\u4e0e\u8f93\u51fa ---\n    IMAGE_PATH = \"./test_image.jpg\"  # &lt;--- [\u5fc5\u987b\u4fee\u6539] \u5f85\u9884\u6d4b\u56fe\u7247\n    # \u7c7b\u522b\u540d\u79f0\u5217\u8868 (\u9700\u6309\u8bad\u7ec3\u65f6\u7684\u987a\u5e8f\u6392\u5217\uff0c\u901a\u5e38\u662f\u6587\u4ef6\u5939\u540d\u7684\u5b57\u6bcd\u987a\u5e8f)\n    CLASS_NAMES = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']  # &lt;--- [\u5fc5\u987b\u4fee\u6539]\n\n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\n# ==========================================\n# 2. \u6838\u5fc3\u903b\u8f91\n# ==========================================\ndef get_transforms(model):\n    \"\"\"\u83b7\u53d6\u5339\u914d\u7684\u9884\u5904\u7406\"\"\"\n    config = resolve_data_config({}, model=model)\n    mean = config.get('mean', [0.485, 0.456, 0.406])\n    std = config.get('std', [0.229, 0.224, 0.225])\n    input_size = config.get('input_size', (3, 224, 224))\n    crop_size = input_size[1]\n\n    print(f\"[Info] \u9884\u5904\u7406\u914d\u7f6e: Size={crop_size}\")\n    return transforms.Compose([\n        transforms.Resize((crop_size, crop_size)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=mean, std=std)\n    ])\n\n\ndef load_trained_model():\n    \"\"\"\u52a0\u8f7d\u67b6\u6784\u4e0e\u6743\u91cd\"\"\"\n    print(f\"[Init] \u521b\u5efa\u6a21\u578b: {Config.MODEL_NAME}\")\n    # \u521b\u5efa\u7a7a\u6a21\u578b\u7ed3\u6784\n    model = timm.create_model(Config.MODEL_NAME, pretrained=False, num_classes=Config.NUM_CLASSES)\n\n    if not os.path.exists(Config.WEIGHT_PATH):\n        raise FileNotFoundError(f\"\u6743\u91cd\u6587\u4ef6\u4e0d\u5b58\u5728: {Config.WEIGHT_PATH}\")\n\n    print(f\"[Load] \u52a0\u8f7d\u6743\u91cd: {Config.WEIGHT_PATH}\")\n    checkpoint = torch.load(Config.WEIGHT_PATH, map_location=Config.DEVICE)\n\n    # \u63d0\u53d6\u53c2\u6570\u5b57\u5178 (\u517c\u5bb9\u53ea\u4fdd\u5b58state_dict\u6216\u5b8c\u6574checkpoint\u7684\u60c5\u51b5)\n    state_dict = checkpoint['state_dict'] if 'state_dict' in checkpoint else checkpoint\n    model.load_state_dict(state_dict)\n\n    model.to(Config.DEVICE)\n    model.eval()\n    return model\n\n\ndef predict(model, img_path, transform):\n    \"\"\"\u63a8\u7406\u5355\u5f20\u56fe\u7247\"\"\"\n    if not os.path.exists(img_path): raise FileNotFoundError(f\"\u56fe\u7247\u4e0d\u5b58\u5728: {img_path}\")\n\n    img_raw = Image.open(img_path).convert('RGB')\n    img_tensor = transform(img_raw).unsqueeze(0).to(Config.DEVICE)  # [1, C, H, W]\n\n    with torch.no_grad():\n        outputs = model(img_tensor)\n        probs = F.softmax(outputs, dim=1)\n\n    # \u83b7\u53d6\u524d3\u540d\n    topk_probs, topk_ids = torch.topk(probs, k=min(3, len(Config.CLASS_NAMES)))\n    return img_raw, topk_probs.cpu().numpy()[0], topk_ids.cpu().numpy()[0]\n\n\n# ==========================================\n# 3. \u4e3b\u7a0b\u5e8f\n# ==========================================\nif __name__ == \"__main__\":\n    try:\n        # \u52a0\u8f7d\u4e0e\u9884\u6d4b\n        model = load_trained_model()\n        tf = get_transforms(model)\n        img, probs, ids = predict(model, Config.IMAGE_PATH, tf)\n\n        # \u6253\u5370\u6587\u672c\u7ed3\u679c\n        print(\"\\n\" + \"=\" * 30)\n        print(\"       PREDICTION RESULT\")\n        print(\"=\" * 30)\n\n        top1_name = Config.CLASS_NAMES[ids[0]]\n        print(f\"\ud83c\udfc6 \u9884\u6d4b\u7ed3\u679c: {top1_name} ({probs[0] * 100:.2f}%)\")\n\n        print(\"\\nTop-3 \u6982\u7387\u5206\u5e03:\")\n        for i in range(len(probs)):\n            name = Config.CLASS_NAMES[ids[i]]\n            print(f\"   {i + 1}. {name:&lt;15} : {probs[i] * 100:.2f}%\")\n\n        # \u53ef\u89c6\u5316\u5c55\u793a\n        plt.figure(figsize=(8, 6))\n        plt.imshow(img)\n        plt.title(f\"Pred: {top1_name} ({probs[0] * 100:.1f}%)\", color='green', fontsize=14)\n        plt.axis('off')\n\n        # \u5728\u56fe\u4e2d\u663e\u793a\u8be6\u7ec6\u6587\u672c\n        text = \"\\n\".join([f\"{Config.CLASS_NAMES[i]}: {p * 100:.1f}%\" for p, i in zip(probs, ids)])\n        plt.text(10, 20, text, bbox=dict(facecolor='white', alpha=0.8), fontsize=10)\n\n        plt.show()\n\n    except Exception as e:\n        print(f\"[Error] {e}\")\n</code></pre>", "tags": ["Python", "\u8ba1\u7b97\u673a\u89c6\u89c9", "\u56fe\u50cf\u5206\u7c7b"]}, {"location": "cv/Split_datasets/", "title": "\u6570\u636e\u96c6\u5212\u5206", "text": "<p>\u6458\u8981\uff1a\u4e00\u4e2a\u5c06\u6570\u636e\u96c6\u4ee5<code>7:2:1</code>\u7684\u6bd4\u4f8b\u5212\u5206\u7684\u4ee3\u7801</p>", "tags": ["Python", "\u6570\u636e\u96c6"]}, {"location": "cv/Split_datasets/#_2", "title": "\u6838\u5fc3\u4ee3\u7801\uff1a", "text": "<pre><code>import os\nimport shutil\nimport random\nfrom tqdm import tqdm\n\n# ==========================================\n# \u914d\u7f6e\u533a\u57df\n# ==========================================\nsource_root = \"./raw_data\"  # &lt;--- [\u8bf7\u4fee\u6539] \u4f60\u7684\u539f\u59cb\u6570\u636e\u96c6\u8def\u5f84\ntarget_root = \"./flower_data\"  # &lt;--- [\u8bf7\u4fee\u6539] \u8f93\u51fa\u8def\u5f84\nsplit_ratio = [0.7, 0.2, 0.1]  # &lt;--- [\u53ef\u4fee\u6539] \u8bad\u7ec3:\u9a8c\u8bc1:\u6d4b\u8bd5 \u6bd4\u4f8b (\u548c\u9700\u4e3a1)\n\n\ndef split_dataset():\n    # \u68c0\u67e5\u539f\u59cb\u8def\u5f84\n    if not os.path.exists(source_root):\n        print(f\"\u9519\u8bef: \u627e\u4e0d\u5230\u8def\u5f84 {source_root}\")\n        return\n\n    # \u83b7\u53d6\u6240\u6709\u7c7b\u522b\u6587\u4ef6\u5939\n    classes = [d for d in os.listdir(source_root) if os.path.isdir(os.path.join(source_root, d))]\n    print(f\"\u53d1\u73b0\u7c7b\u522b: {classes}\")\n\n    # \u521b\u5efa\u76ee\u6807\u6587\u4ef6\u5939\u7ed3\u6784\n    for split in ['train', 'val', 'test']:\n        for cls in classes:\n            os.makedirs(os.path.join(target_root, split, cls), exist_ok=True)\n\n    # \u5f00\u59cb\u5212\u5206\n    for cls in tqdm(classes, desc=\"\u6b63\u5728\u5212\u5206\u6570\u636e\u96c6\"):\n        cls_path = os.path.join(source_root, cls)\n        # \u83b7\u53d6\u8be5\u7c7b\u522b\u4e0b\u6240\u6709\u56fe\u7247\u6587\u4ef6\n        images = [f for f in os.listdir(cls_path) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n\n        # \u968f\u673a\u6253\u4e71\n        random.shuffle(images)\n\n        # \u8ba1\u7b97\u5207\u5206\u70b9\n        num_total = len(images)\n        num_train = int(num_total * split_ratio[0])\n        num_val = int(num_total * split_ratio[1])\n        # \u5269\u4e0b\u7684\u90fd\u7ed9\u6d4b\u8bd5\u96c6\uff0c\u907f\u514d\u56e0\u53d6\u6574\u4e22\u5931\u6570\u636e\n\n        train_imgs = images[:num_train]\n        val_imgs = images[num_train: num_train + num_val]\n        test_imgs = images[num_train + num_val:]\n\n        # \u590d\u5236\u6587\u4ef6\u51fd\u6570\n        def copy_files(file_list, split_name):\n            for file_name in file_list:\n                src = os.path.join(cls_path, file_name)\n                dst = os.path.join(target_root, split_name, cls, file_name)\n                shutil.copy(src, dst)\n\n        # \u6267\u884c\u590d\u5236\n        copy_files(train_imgs, 'train')\n        copy_files(val_imgs, 'val')\n        copy_files(test_imgs, 'test')\n\n        print(f\"\u7c7b\u522b [{cls}]: \u603b\u6570 {num_total} -&gt; Train:{len(train_imgs)} Val:{len(val_imgs)} Test:{len(test_imgs)}\")\n\n    print(f\"\\n[Done] \u6570\u636e\u96c6\u5212\u5206\u5b8c\u6210\uff01\u4fdd\u5b58\u5728: {target_root}\")\n\n\nif __name__ == \"__main__\":\n    split_dataset()\n</code></pre>", "tags": ["Python", "\u6570\u636e\u96c6"]}, {"location": "posts/example/", "title": "\u6587\u7ae0\u6807\u9898 (\u4f8b\u5982\uff1a\u57fa\u4e8e Huffman \u7f16\u7801\u7684\u6587\u4ef6\u538b\u7f29\u5668\u5f00\u53d1\u5fc3\u5f97)", "text": "<p>\u6458\u8981\uff1a\u8fd9\u91cc\u5199\u4e00\u4e24\u53e5\u7b80\u77ed\u7684\u4ecb\u7ecd\uff0c\u6bd4\u5982\u8fd9\u7bc7\u6587\u7ae0\u89e3\u51b3\u4e86\u4ec0\u4e48\u95ee\u9898\uff0c\u6216\u8005\u4f60\u5b66\u5230\u4e86\u4ec0\u4e48\u6838\u5fc3\u77e5\u8bc6\u3002</p>", "tags": ["Python", "\u7b97\u6cd5", "\u5b66\u4e60\u7b14\u8bb0"]}, {"location": "posts/example/#1", "title": "1. \u80cc\u666f\u4ecb\u7ecd", "text": "<p>\u5728\u6b64\u5904\u63cf\u8ff0\u4e3a\u4ec0\u4e48\u8981\u505a\u8fd9\u4e2a\u9879\u76ee\uff0c\u6216\u8005\u4e3a\u4ec0\u4e48\u8981\u5b66\u8fd9\u4e2a\u77e5\u8bc6\u70b9\u3002 \u4f8b\u5982\uff1a\u201c\u6700\u8fd1\u4e3a\u4e86\u51c6\u5907 C \u8bed\u8a00\u7f16\u7a0b\u6bd4\u8d5b\uff0c\u6211\u51b3\u5b9a\u6311\u6218\u5199\u4e00\u4e2a\u6587\u4ef6\u538b\u7f29\u5de5\u5177...\u201d</p>", "tags": ["Python", "\u7b97\u6cd5", "\u5b66\u4e60\u7b14\u8bb0"]}, {"location": "posts/example/#2", "title": "2. \u6838\u5fc3\u539f\u7406 (\u53ef\u4ee5\u4f7f\u7528\u516c\u5f0f\u4e86\uff01)", "text": "<p>\u8fd9\u91cc\u89e3\u91ca\u7406\u8bba\u90e8\u5206\u3002\u56e0\u4e3a\u6211\u4eec\u5f00\u542f\u4e86 MathJax\uff0c\u4f60\u53ef\u4ee5\u5c3d\u60c5\u5c55\u793a\u6570\u5b66\u4e4b\u7f8e\uff1a</p> <p>Huffman \u6811\u7684\u5e26\u6743\u8def\u5f84\u957f\u5ea6 (WPL) \u8ba1\u7b97\u516c\u5f0f\u4e3a\uff1a $\\(WPL = \\sum_{i=1}^{n} w_i l_i\\)$</p>", "tags": ["Python", "\u7b97\u6cd5", "\u5b66\u4e60\u7b14\u8bb0"]}, {"location": "posts/example/#3", "title": "3. \u4ee3\u7801\u5b9e\u73b0", "text": "<p>\u5c55\u793a\u4f60\u7684\u6838\u5fc3\u4ee3\u7801\uff0c\u8bb0\u5f97\u7528\u4e09\u4e2a\u53cd\u5f15\u53f7\u5305\u88f9\uff1a</p> <pre><code>// \u8fd9\u91cc\u7c98\u8d34\u4f60\u7684 C \u8bed\u8a00\u6216 Python \u4ee3\u7801\ntypedef struct {\n    int weight;\n    int parent, lchild, rchild;\n} HTNode, *HuffmanTree;\n</code></pre>", "tags": ["Python", "\u7b97\u6cd5", "\u5b66\u4e60\u7b14\u8bb0"]}]}