{"config": {"lang": ["en"], "separator": "[\\s\\u200b\\u3000\\-\u3001\u3002\uff0c\uff0e\uff1f\uff01\uff1b]+", "pipeline": ["stemmer"], "fields": {"title": {"boost": 1000.0}, "text": {"boost": 1.0}, "tags": {"boost": 1000000.0}}}, "docs": [{"location": "", "title": "\u6b22\u8fce\u6765\u5230\u6211\u7684\u5b66\u4e60\u7a7a\u95f4", "text": "<p>\u8fd9\u91cc\u662f\u6211\u8bb0\u5f55 Python \u5b66\u4e60\u548c\u6280\u672f\u63a2\u7d22\u7684\u5730\u65b9\u3002</p>"}, {"location": "#_2", "title": "\u4eca\u65e5\u76ee\u6807", "text": "<p>\u8fd9\u662f\u4e8c\u7ea7\u6807\u9898\uff0c\u7528\u6765\u7ed9\u6587\u7ae0\u5206\u6bb5\u3002</p> <ul> <li> \u642d\u5efa\u535a\u5ba2\u73af\u5883</li> <li> \u5b66\u4e60 Markdown \u8bed\u6cd5</li> <li> \u5199\u4e0b\u7b2c\u4e00\u884c Python \u4ee3\u7801</li> </ul>"}, {"location": "#_3", "title": "\u6211\u7684\u7b2c\u4e00\u6bb5\u4ee3\u7801", "text": "<p>Markdown \u6700\u5f3a\u5927\u7684\u5730\u65b9\u5c31\u662f\u53ef\u4ee5\u9ad8\u4eae\u4ee3\u7801\uff0c\u770b\u4e0b\u9762\uff1a</p> <pre><code># \u8fd9\u662f\u4e00\u4e2a\u4ee3\u7801\u5757\uff0c\u7528\u4e09\u4e2a\u53cd\u5f15\u53f7\u5305\u88f9\ndef hello_blog():\n    print(\"Hello, World!\")\n\nhello_blog()\n</code></pre>"}, {"location": "build_blog/", "title": "\u6211\u662f\u5982\u4f55\u7528 Python \u642d\u5efa\u4e2a\u4eba\u535a\u5ba2\u7684", "text": "<p>\u8fd9\u662f\u6211\u535a\u5ba2\u7684\u7b2c\u4e00\u7bc7\u6b63\u5f0f\u6280\u672f\u6587\u7ae0\u3002\u5728\u8fd9\u7bc7\u6587\u7ae0\u91cc\uff0c\u6211\u60f3\u5206\u4eab\u6211\u662f\u5982\u4f55\u5229\u7528 Python \u548c\u5f00\u6e90\u5de5\u5177\uff0c\u5728\u96f6\u6210\u672c\u7684\u60c5\u51b5\u4e0b\u642d\u5efa\u8d77\u8fd9\u4e2a\u72ec\u7acb\u535a\u5ba2\u7684\u3002</p>"}, {"location": "build_blog/#_1", "title": "\u4e3a\u4ec0\u4e48\u9009\u62e9\u201c\u6298\u817e\u201d\uff1f", "text": "<p>\u5176\u5b9e\u73b0\u5728\u7684\u5199\u4f5c\u5e73\u53f0\u5f88\u591a\uff08\u77e5\u4e4e\u3001\u516c\u4f17\u53f7\u7b49\uff09\uff0c\u4f46\u6211\u4f9d\u7136\u9009\u62e9\u81ea\u5df1\u642d\u5efa\u4e00\u4e2a\u535a\u5ba2\uff0c\u539f\u56e0\u5f88\u7b80\u5355\uff1a</p> <ol> <li>\u6570\u636e\u81ea\u4e3b\uff1a\u6240\u6709\u7684\u6587\u7ae0\u6e90\u7801\u90fd\u4fdd\u5b58\u5728\u6211\u81ea\u5df1\u7684 GitHub \u4ed3\u5e93\u91cc\uff0c\u4e0d\u4f1a\u56e0\u4e3a\u5e73\u53f0\u89c4\u5219\u53d8\u52a8\u800c\u4e22\u5931\u3002</li> <li>\u6781\u5ba2\u7cbe\u795e\uff1a\u4f5c\u4e3a\u4e00\u540d\u7f16\u7a0b\u5b66\u4e60\u8005\uff0c\u7528\u4ee3\u7801\u6784\u5efa\u81ea\u5df1\u7684\u201c\u540e\u82b1\u56ed\u201d\u672c\u8eab\u5c31\u662f\u4e00\u4ef6\u5f88\u6709\u6210\u5c31\u611f\u7684\u4e8b\u3002</li> <li>\u6280\u672f\u79ef\u7d2f\uff1a\u5728\u642d\u5efa\u8fc7\u7a0b\u4e2d\uff0c\u6211\u987a\u4fbf\u719f\u6089\u4e86 Python \u73af\u5883\u3001\u547d\u4ee4\u884c\u64cd\u4f5c\u548c Git \u7248\u672c\u63a7\u5236\u3002</li> </ol>"}, {"location": "build_blog/#_2", "title": "\u6211\u7684\u6280\u672f\u6808", "text": "<p>\u6211\u7684\u535a\u5ba2\u5e76\u4e0d\u662f\u4ece\u96f6\u5f00\u59cb\u5199 HTML/CSS\uff0c\u800c\u662f\u7ad9\u5728\u4e86\u5de8\u4eba\u7684\u80a9\u8180\u4e0a\u3002\u4ee5\u4e0b\u662f\u6211\u4f7f\u7528\u7684\u6838\u5fc3\u5de5\u5177\uff1a</p> \u5de5\u5177 \u4f5c\u7528 \u5907\u6ce8 Python \u57fa\u7840\u8bed\u8a00\u73af\u5883 \u5f3a\u5927\u7684\u751f\u6001\u652f\u6301 MkDocs \u9759\u6001\u7f51\u7ad9\u751f\u6210\u5668 \u628a Markdown \u8f6c\u6362\u6210\u7f51\u9875\u7684\u5f15\u64ce Material \u4e3b\u9898\u76ae\u80a4 \u63d0\u4f9b\u7f8e\u89c2\u7684 UI \u548c\u54cd\u5e94\u5f0f\u8bbe\u8ba1 GitHub Pages \u7f51\u7ad9\u6258\u7ba1 \u514d\u8d39\u7684\u4e91\u7aef\u670d\u52a1\u5668 PyCharm \u6211\u7684\u5f00\u53d1\u795e\u5668 \u7f16\u5199\u548c\u7ba1\u7406\u4ee3\u7801\u7684\u5730\u65b9"}, {"location": "build_blog/#_3", "title": "\u642d\u5efa\u8fc7\u7a0b\u590d\u76d8", "text": "<p>\u6574\u4e2a\u8fc7\u7a0b\u6bd4\u6211\u60f3\u8c61\u4e2d\u8981\u7b80\u5355\uff0c\u6838\u5fc3\u53ea\u6709\u4e09\u6b65\uff1a</p>"}, {"location": "build_blog/#1", "title": "1. \u5b89\u88c5\u201c\u5f15\u64ce\u201d", "text": "<p>\u5229\u7528 Python \u7684\u5305\u7ba1\u7406\u5de5\u5177 pip\uff0c\u5b89\u88c5 MkDocs \u548c Material \u4e3b\u9898\uff1a</p> <pre><code>pip install mkdocs-material\n</code></pre>"}, {"location": "build_blog/#2", "title": "2. \u521d\u59cb\u5316\u9879\u76ee", "text": "<p>\u4e00\u884c\u547d\u4ee4\u751f\u6210\u535a\u5ba2\u7684\u57fa\u7840\u9aa8\u67b6\uff1a</p> <pre><code>mkdocs new .\n</code></pre>"}, {"location": "build_blog/#3", "title": "3. \u914d\u7f6e\u4e0e\u53d1\u5e03", "text": "<p>\u5728 <code>mkdocs.yml</code> \u4e2d\u914d\u7f6e\u597d\u7f51\u7ad9\u540d\u79f0\u548c\u4e3b\u9898\u540e\uff0c\u4f7f\u7528 MkDocs \u63d0\u4f9b\u7684\u547d\u4ee4\u4e00\u952e\u90e8\u7f72\u5230 GitHub\uff1a</p> <pre><code>mkdocs gh-deploy\n</code></pre> <p>\u5c31\u662f\u8fd9\u4e48\u7b80\u5355\uff01\u5269\u4e0b\u7684\u5de5\u4f5c\uff0c\u5c31\u662f\u4e13\u6ce8\u4e8e\u7528 Markdown \u5199\u4f5c\u4e86\u3002</p>"}, {"location": "build_blog/#_4", "title": "\u9047\u5230\u7684\u5751\u4e0e\u89e3\u51b3", "text": "<p>\u5728\u642d\u5efa\u8fc7\u7a0b\u4e2d\uff0c\u6211\u4e5f\u9047\u5230\u4e86\u4e00\u4e9b\u5c0f\u63d2\u66f2\uff08\u6bd4\u5982 Markdown \u4ee3\u7801\u5757\u7684\u8bed\u6cd5\u95ee\u9898\uff09\uff0c\u4f46\u901a\u8fc7\u67e5\u9605\u6587\u6863\u548c\u8c03\u8bd5\uff0c\u6700\u7ec8\u90fd\u89e3\u51b3\u4e86\u3002\u8fd9\u4e5f\u8ba9\u6211\u660e\u767d\uff1a\u7f16\u7a0b\u4e0d\u4ec5\u4ec5\u662f\u5199\u4ee3\u7801\uff0c\u66f4\u662f\u89e3\u51b3\u95ee\u9898\u7684\u8fc7\u7a0b\u3002</p>"}, {"location": "build_blog/#_5", "title": "\u5199\u5728\u6700\u540e", "text": "<p>\u8fd9\u4e2a\u535a\u5ba2\u76ee\u524d\u8fd8\u5f88\u7b80\u6d01\uff0c\u672a\u6765\u6211\u8ba1\u5212\uff1a</p> <ul> <li> \u8bb0\u5f55\u6211\u7684 C \u8bed\u8a00\u548c Python \u5b66\u4e60\u7b14\u8bb0</li> <li> \u5c1d\u8bd5\u4fee\u6539\u535a\u5ba2\u7684\u6837\u5f0f\uff08CSS\uff09</li> <li> \u575a\u6301\u6bcf\u5468\u66f4\u65b0</li> </ul> <p>\u5982\u679c\u4f60\u4e5f\u5bf9\u642d\u5efa\u535a\u5ba2\u611f\u5174\u8da3\uff0c\u6b22\u8fce\u4e0e\u6211\u4ea4\u6d41\uff01</p>"}, {"location": "guide/", "title": "\u535a\u5ba2\u65e5\u5e38\u7ef4\u62a4\u624b\u518c", "text": "<p>\u8fd9\u662f\u6211\u7684\u535a\u5ba2\u7ba1\u7406\u5907\u5fd8\u5f55\u3002\u4ee5\u540e\u6bcf\u6b21\u66f4\u65b0\u6587\u7ae0\uff0c\u6309\u7167\u8fd9\u4e2a\u6d41\u7a0b\u64cd\u4f5c\u5373\u53ef\u3002</p>"}, {"location": "guide/#4", "title": "\u4e00\u3001 \u65e5\u5e38\u66f4\u65b0\u6d41\u7a0b (4\u6b65\u6cd5)", "text": ""}, {"location": "guide/#1-write", "title": "\u7b2c 1 \u6b65\uff1a\u521b\u4f5c (Write)", "text": "<p>\u5728 <code>docs</code> \u6587\u4ef6\u5939\u4e0b\u65b0\u5efa <code>.md</code> \u6587\u4ef6\uff0c\u4f7f\u7528 Markdown \u8bed\u6cd5\u7f16\u5199\u5185\u5bb9\u3002</p>"}, {"location": "guide/#2-preview", "title": "\u7b2c 2 \u6b65\uff1a\u9884\u89c8 (Preview)", "text": "<p>\u5728 PyCharm \u7684 Terminal \u4e2d\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\uff0c\u542f\u52a8\u672c\u5730\u670d\u52a1\u5668\uff1a</p> <pre><code>mkdocs serve\n</code></pre> <ul> <li>\u6253\u5f00\u6d4f\u89c8\u5668\u8bbf\u95ee\uff1a[http://127.0.0.1:8000]</li> <li>\u68c0\u67e5\u6392\u7248\u548c\u5185\u5bb9\uff0c\u786e\u8ba4\u65e0\u8bef\u540e\u6309 <code>Ctrl + C</code> \u505c\u6b62\u670d\u52a1\u3002</li> </ul>"}, {"location": "guide/#3-deploy", "title": "\u7b2c 3 \u6b65\uff1a\u53d1\u5e03 (Deploy)", "text": "<p>\u5c06\u751f\u6210\u7684\u9759\u6001\u7f51\u9875\u63a8\u9001\u5230 GitHub Pages\uff0c\u8ba9\u7f51\u7ad9\u4e0a\u7ebf\uff1a</p> <pre><code>mkdocs gh-deploy\n</code></pre>"}, {"location": "guide/#4-backup", "title": "\u7b2c 4 \u6b65\uff1a\u5907\u4efd\u6e90\u7801 (Backup)", "text": "<p>\u91cd\u8981\uff01 \u8fd9\u4e00\u6b65\u662f\u4e3a\u4e86\u9632\u6b62\u6e90\u7801\u4e22\u5931\u3002\u5c06\u672c\u5730\u7684 Markdown \u539f\u7a3f\u540c\u6b65\u5230 GitHub \u4ed3\u5e93\uff1a</p> <pre><code>git add .\ngit commit -m \"\u65e5\u5e38\u66f4\u65b0\uff1a\u65b0\u589e\u6587\u7ae0\"\ngit push\n</code></pre>"}, {"location": "guide/#_2", "title": "\u4e8c\u3001 \u8fdb\u9636\u914d\u7f6e\uff1a\u7ba1\u7406\u83dc\u5355\u680f", "text": "<p>\u5982\u679c\u8981\u8c03\u6574\u6587\u7ae0\u5728\u5de6\u4fa7\u5bfc\u822a\u680f\u7684\u987a\u5e8f\uff0c\u9700\u8981\u4fee\u6539\u6839\u76ee\u5f55\u4e0b\u7684 <code>mkdocs.yml</code> \u6587\u4ef6\u3002</p> <p>\u627e\u5230 <code>nav</code> \u914d\u7f6e\u9879\uff08\u5982\u679c\u6ca1\u6709\u5c31\u81ea\u5df1\u52a0\u4e0a\uff09\uff1a</p> <pre><code>site_name: \u6211\u7684 Python \u5b66\u4e60\u7b14\u8bb0\ntheme:\n  name: material\n\n# \u5bfc\u822a\u680f\u914d\u7f6e\nnav:\n  - \u9996\u9875: index.md\n  - \u535a\u5ba2\u6307\u5357: guide.md  # &lt;--- \u8fd9\u5c31\u662f\u6211\u73b0\u5728\u8fd9\u7bc7\u6587\u7ae0\n  - Python\u7b14\u8bb0:\n      - \u53d8\u91cf\u4e0e\u7c7b\u578b: python_basic.md\n  - \u968f\u60f3: thoughts.md\n</code></pre> <p>\u6ce8\u610f\uff1a\u4fee\u6539 <code>mkdocs.yml</code> \u4e4b\u540e\uff0c\u901a\u5e38\u9700\u8981\u91cd\u542f <code>mkdocs serve</code> \u624d\u80fd\u770b\u5230\u6548\u679c\u3002</p>"}, {"location": "cv/Image_Classification/", "title": "\u56fe\u50cf\u5206\u7c7b\u6a21\u578b\u901a\u7528\u6a21\u677f", "text": "<p>\u6458\u8981\uff1a\u4e00\u4e2a\u53ef\u914d\u7f6e\u7684\u4ee3\u7801\u6a21\u677f\uff0c\u7528\u4e8e\u8bad\u7ec3\u56fe\u50cf\u5206\u7c7b\u6a21\u578b</p>", "tags": ["Python", "\u8ba1\u7b97\u673a\u89c6\u89c9", "\u56fe\u50cf\u5206\u7c7b"]}, {"location": "cv/Image_Classification/#_2", "title": "\u6838\u5fc3\u4ee3\u7801\uff1a", "text": "<pre><code>import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nimport timm\nfrom timm.data import resolve_data_config\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\n# \u5c1d\u8bd5\u5bfc\u5165\u9ad8\u7ea7\u8bc4\u4f30\u7ed8\u56fe\u5e93\uff0c\u5982\u679c\u6ca1\u5b89\u88c5\u5219\u8df3\u8fc7\ntry:\n    from sklearn.metrics import classification_report, confusion_matrix\n    import seaborn as sns\n\n    HAS_SKLEARN = True\nexcept ImportError:\n    HAS_SKLEARN = False\n    print(\"[Warning] \u672a\u5b89\u88c5 scikit-learn \u6216 seaborn\uff0c\u5c06\u8df3\u8fc7\u6df7\u6dc6\u77e9\u9635\u7ed8\u5236\u3002\u5efa\u8bae\u5b89\u88c5: pip install scikit-learn seaborn\")\n\n\n# ==========================================\n# 1. \u914d\u7f6e\u533a\u57df [\u53ef\u5fae\u8c03]\n# ==========================================\nclass Config:\n    # \u8def\u5f84\u8bbe\u7f6e\n    data_root = \"flower_data\"  # &lt;--- [\u53ef\u4fee\u6539] \u6570\u636e\u96c6\u6839\u76ee\u5f55 (\u9700\u5305\u542b train/val/test \u6587\u4ef6\u5939)\n    save_dir = \"./results\"  # &lt;--- [\u53ef\u4fee\u6539] \u7ed3\u679c\u4fdd\u5b58\u8def\u5f84\n\n    # \u6a21\u578b\u8bbe\u7f6e\n    model_name = \"resnet50\"  # &lt;--- [\u53ef\u5fae\u8c03] \u6a21\u578b\u540d\u79f0 (\u5982 resnet18, efficientnet_b0, mobilenetv3_large_100)\n    num_classes = 5  # &lt;--- [\u53ef\u4fee\u6539] \u5206\u7c7b\u7c7b\u522b\u6570\n    pretrained = True  # &lt;--- [\u53ef\u5fae\u8c03] \u662f\u5426\u4f7f\u7528\u5728\u7ebf\u9884\u8bad\u7ec3\u6743\u91cd\n    checkpoint_path = \"\"  # &lt;--- [\u53ef\u5fae\u8c03] \u672c\u5730\u6743\u91cd\u8def\u5f84 (\u4ec5\u5f53 pretrained=False \u65f6\u4f7f\u7528)\n\n    # \u8bad\u7ec3\u8d85\u53c2\u6570\n    batch_size = 32  # &lt;--- [\u53ef\u5fae\u8c03] \u6279\u6b21\u5927\u5c0f\n    epochs = 20  # &lt;--- [\u53ef\u5fae\u8c03] \u8bad\u7ec3\u8f6e\u6570\n    lr = 1e-4  # &lt;--- [\u53ef\u5fae\u8c03] \u5b66\u4e60\u7387\n    weight_decay = 1e-4  # &lt;--- [\u53ef\u5fae\u8c03] \u6743\u91cd\u8870\u51cf (L2\u6b63\u5219\u5316)\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\n# ==========================================\n# 2. \u51c6\u5907\u5de5\u4f5c\uff1a\u6a21\u578b\u4e0e\u6570\u636e\n# ==========================================\ndef get_model_and_transforms():\n    # 1. \u521b\u5efa\u6a21\u578b\n    model = timm.create_model(\n        Config.model_name,\n        pretrained=Config.pretrained,\n        checkpoint_path=Config.checkpoint_path,\n        num_classes=Config.num_classes\n    )\n    model.to(Config.device)\n\n    # 2. \u83b7\u53d6\u9ed8\u8ba4\u914d\u7f6e\u5e76\u6253\u5370\n    config = resolve_data_config({}, model=model)\n    # print(f\"[Info] Model Config: {config}\")\n\n    # 3. \u5b9a\u4e49\u6570\u636e\u589e\u5f3a [\u53ef\u5fae\u8c03]\n    # \u8bad\u7ec3\u96c6\uff1a\u9700\u8981\u589e\u5f3a\n    train_transform = transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.CenterCrop(224),  # \u6216\u4f7f\u7528 RandomResizedCrop(224)\n        transforms.RandomHorizontalFlip(0.5),\n        transforms.RandomRotation(15),  # \u968f\u673a\u65cb\u8f6c\n        transforms.ColorJitter(brightness=0.1, contrast=0.1),  # \u989c\u8272\u6296\u52a8\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\n    # \u9a8c\u8bc1\u96c6/\u6d4b\u8bd5\u96c6\uff1a\u4e0d\u9700\u8981\u589e\u5f3a\uff0c\u53ea\u9700\u8981\u6807\u51c6\u5316\n    val_test_transform = transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\n    return model, train_transform, val_test_transform\n\n\n# ==========================================\n# 3. \u6838\u5fc3\u529f\u80fd\uff1a\u8bad\u7ec3\u3001\u9a8c\u8bc1\u3001\u6d4b\u8bd5\n# ==========================================\ndef train_one_epoch(model, loader, criterion, optimizer, epoch):\n    model.train()\n    total_loss, total_correct = 0.0, 0\n\n    bar = tqdm(loader, desc=f\"Epoch {epoch}/{Config.epochs} [Train]\")\n    for imgs, labels in bar:\n        imgs, labels = imgs.to(Config.device), labels.to(Config.device)\n\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item() * imgs.size(0)\n        total_correct += (outputs.argmax(1) == labels).sum().item()\n\n        bar.set_postfix(loss=loss.item())\n\n    return total_loss / len(loader.dataset), total_correct / len(loader.dataset)\n\n\n@torch.no_grad()\ndef validate(model, loader, criterion, epoch, phase=\"Val\"):\n    model.eval()\n    total_loss, total_correct = 0.0, 0\n\n    bar = tqdm(loader, desc=f\"Epoch {epoch}/{Config.epochs} [{phase}]  \")\n    for imgs, labels in bar:\n        imgs, labels = imgs.to(Config.device), labels.to(Config.device)\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n\n        total_loss += loss.item() * imgs.size(0)\n        total_correct += (outputs.argmax(1) == labels).sum().item()\n        bar.set_postfix(loss=loss.item())\n\n    return total_loss / len(loader.dataset), total_correct / len(loader.dataset)\n\n\ndef evaluate_test_set(model, test_loader, class_names):\n    \"\"\"\n    \u72ec\u7acb\u6d4b\u8bd5\u51fd\u6570\uff1a\u8f93\u51fa\u5206\u7c7b\u62a5\u544a\u548c\u6df7\u6dc6\u77e9\u9635\n    \"\"\"\n    if not HAS_SKLEARN:\n        print(\"[Info] \u8df3\u8fc7\u8be6\u7ec6\u6d4b\u8bd5\u62a5\u544a\uff08\u7f3a\u5c11sklearn\u5e93\uff09\")\n        return\n\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    print(f\"\\n[Test] \u6b63\u5728\u8fdb\u884c\u6700\u7ec8\u6d4b\u8bd5\u96c6\u8bc4\u4f30...\")\n    with torch.no_grad():\n        for imgs, labels in tqdm(test_loader, desc=\"Testing\"):\n            imgs = imgs.to(Config.device)\n            labels = labels.to(Config.device)\n            outputs = model(imgs)\n            preds = outputs.argmax(dim=1)\n\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    # 1. \u6253\u5370\u5206\u7c7b\u62a5\u544a (Precision, Recall, F1)\n    print(\"\\n\" + \"=\" * 50)\n    print(\"FINAL TEST REPORT\")\n    print(\"=\" * 50)\n    print(classification_report(all_labels, all_preds, target_names=class_names, digits=4))\n\n    # 2. \u7ed8\u5236\u6df7\u6dc6\u77e9\u9635\n    plt.figure(figsize=(10, 8))\n    cm = confusion_matrix(all_labels, all_preds)\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=class_names, yticklabels=class_names)\n    plt.xlabel('Predicted Label')\n    plt.ylabel('True Label')\n    plt.title('Confusion Matrix')\n    save_path = os.path.join(Config.save_dir, 'confusion_matrix.png')\n    plt.savefig(save_path)\n    print(f\"[Info] \u6df7\u6dc6\u77e9\u9635\u5df2\u4fdd\u5b58\u81f3: {save_path}\")\n    # plt.show()\n\n\n# ==========================================\n# 4. \u8f85\u52a9\u529f\u80fd\uff1a\u753b\u56fe\n# ==========================================\ndef plot_history(history, save_dir):\n    epochs = range(1, len(history['train_acc']) + 1)\n\n    plt.figure(figsize=(12, 5))\n\n    # Accuracy Curve\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, history['train_acc'], 'b-o', label='Train Acc')\n    plt.plot(epochs, history['val_acc'], 'r-o', label='Val Acc')\n    plt.title('Training and Validation Accuracy')\n    plt.legend()\n\n    # Loss Curve\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, history['train_loss'], 'b-o', label='Train Loss')\n    plt.plot(epochs, history['val_loss'], 'r-o', label='Val Loss')\n    plt.title('Training and Validation Loss')\n    plt.legend()\n\n    plt.tight_layout()\n    plt.savefig(os.path.join(save_dir, 'training_curve.png'))\n    print(f\"[Info] \u8bad\u7ec3\u66f2\u7ebf\u5df2\u4fdd\u5b58\u81f3: {os.path.join(save_dir, 'training_curve.png')}\")\n\n\n# ==========================================\n# 5. \u4e3b\u7a0b\u5e8f\u5165\u53e3\n# ==========================================\nif __name__ == \"__main__\":\n    # \u521d\u59cb\u5316\n    os.makedirs(Config.save_dir, exist_ok=True)\n    model, train_tf, val_test_tf = get_model_and_transforms()\n\n    # \u52a0\u8f7d\u6570\u636e\u96c6\n    # \u5047\u8bbe\u76ee\u5f55\u7ed3\u6784\u4e3a: data_root/train, data_root/val, data_root/test\n    train_ds = datasets.ImageFolder(os.path.join(Config.data_root, \"train\"), transform=train_tf)\n    val_ds = datasets.ImageFolder(os.path.join(Config.data_root, \"val\"), transform=val_test_tf)\n\n    train_loader = DataLoader(train_ds, batch_size=Config.batch_size, shuffle=True, num_workers=4)\n    val_loader = DataLoader(val_ds, batch_size=Config.batch_size, shuffle=False, num_workers=4)\n\n    print(f\"[Data] Train: {len(train_ds)} | Val: {len(val_ds)}\")\n\n    # \u5b9a\u4e49\u4f18\u5316\u5668\u4e0e\u635f\u5931\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=Config.lr, weight_decay=Config.weight_decay)\n\n    # ---------------------------\n    # Phase 1: \u8bad\u7ec3\u5faa\u73af\n    # ---------------------------\n    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n    best_acc = 0.0\n\n    print(f\"\\n[Start] \u5f00\u59cb\u8bad\u7ec3... (Total Epochs: {Config.epochs})\")\n    for epoch in range(1, Config.epochs + 1):\n        t_loss, t_acc = train_one_epoch(model, train_loader, criterion, optimizer, epoch)\n        v_loss, v_acc = validate(model, val_loader, criterion, epoch, phase=\"Val\")\n\n        history['train_loss'].append(t_loss)\n        history['train_acc'].append(t_acc)\n        history['val_loss'].append(v_loss)\n        history['val_acc'].append(v_acc)\n\n        print(f\"Epoch {epoch}: Train Acc: {t_acc:.4f} | Val Acc: {v_acc:.4f}\")\n\n        # \u4fdd\u5b58\u6700\u4f73\u6a21\u578b\n        if v_acc &gt; best_acc:\n            best_acc = v_acc\n            torch.save(model.state_dict(), os.path.join(Config.save_dir, \"best_model.pth\"))\n            print(f\" -&gt; \ud83c\udf1f \u6700\u4f73\u6a21\u578b\u5df2\u66f4\u65b0 (Acc: {best_acc:.4f})\")\n\n    # \u7ed8\u5236\u66f2\u7ebf\n    plot_history(history, Config.save_dir)\n\n    # ---------------------------\n    # Phase 2: \u6d4b\u8bd5\u96c6\u8bc4\u4f30\n    # ---------------------------\n    print(\"\\n\" + \"=\" * 30)\n    print(\"\u8fdb\u5165\u6d4b\u8bd5\u9636\u6bb5 (Test Phase)\")\n    print(\"=\" * 30)\n\n    # 1. \u52a0\u8f7d\u6d4b\u8bd5\u6570\u636e (\u6ce8\u610f\u4f7f\u7528 val_test_tf\uff0c\u4e0d\u505a\u589e\u5f3a)\n    test_dir = os.path.join(Config.data_root, \"test\")\n    if os.path.exists(test_dir):\n        test_ds = datasets.ImageFolder(test_dir, transform=val_test_tf)\n        test_loader = DataLoader(test_ds, batch_size=Config.batch_size, shuffle=False, num_workers=4)\n\n        # 2. \u5fc5\u987b\u91cd\u65b0\u52a0\u8f7d\u6700\u4f73\u6743\u91cd (Best Weights)\n        best_path = os.path.join(Config.save_dir, \"best_model.pth\")\n        model.load_state_dict(torch.load(best_path))\n        print(f\"[Info] \u5df2\u52a0\u8f7d\u6700\u4f73\u6743\u91cd\u7528\u4e8e\u6d4b\u8bd5: {best_path}\")\n\n        # 3. \u6267\u884c\u8be6\u7ec6\u8bc4\u4f30\n        evaluate_test_set(model, test_loader, train_ds.classes)\n\n    else:\n        print(f\"[Warning] \u672a\u627e\u5230\u6d4b\u8bd5\u96c6\u6587\u4ef6\u5939 {test_dir}\uff0c\u8df3\u8fc7\u6d4b\u8bd5\u6b65\u9aa4\u3002\")\n\n    print(\"\\n[Done] \u6240\u6709\u4efb\u52a1\u5b8c\u6210\u3002\")\n</code></pre>", "tags": ["Python", "\u8ba1\u7b97\u673a\u89c6\u89c9", "\u56fe\u50cf\u5206\u7c7b"]}, {"location": "cv/Split_datasets/", "title": "\u6570\u636e\u96c6\u5212\u5206", "text": "<p>\u6458\u8981\uff1a\u4e00\u4e2a\u5c06\u6570\u636e\u96c6\u4ee5<code>7:2:1</code>\u7684\u6bd4\u4f8b\u5212\u5206\u7684\u4ee3\u7801</p>", "tags": ["Python", "\u6570\u636e\u96c6"]}, {"location": "cv/Split_datasets/#_2", "title": "\u6838\u5fc3\u4ee3\u7801\uff1a", "text": "<pre><code>import os\nimport shutil\nimport random\nfrom tqdm import tqdm\n\n# ==========================================\n# \u914d\u7f6e\u533a\u57df\n# ==========================================\nsource_root = \"./raw_data\"  # &lt;--- [\u8bf7\u4fee\u6539] \u4f60\u7684\u539f\u59cb\u6570\u636e\u96c6\u8def\u5f84\ntarget_root = \"./flower_data\"  # &lt;--- [\u8bf7\u4fee\u6539] \u8f93\u51fa\u8def\u5f84\nsplit_ratio = [0.7, 0.2, 0.1]  # &lt;--- [\u53ef\u4fee\u6539] \u8bad\u7ec3:\u9a8c\u8bc1:\u6d4b\u8bd5 \u6bd4\u4f8b (\u548c\u9700\u4e3a1)\n\n\ndef split_dataset():\n    # \u68c0\u67e5\u539f\u59cb\u8def\u5f84\n    if not os.path.exists(source_root):\n        print(f\"\u9519\u8bef: \u627e\u4e0d\u5230\u8def\u5f84 {source_root}\")\n        return\n\n    # \u83b7\u53d6\u6240\u6709\u7c7b\u522b\u6587\u4ef6\u5939\n    classes = [d for d in os.listdir(source_root) if os.path.isdir(os.path.join(source_root, d))]\n    print(f\"\u53d1\u73b0\u7c7b\u522b: {classes}\")\n\n    # \u521b\u5efa\u76ee\u6807\u6587\u4ef6\u5939\u7ed3\u6784\n    for split in ['train', 'val', 'test']:\n        for cls in classes:\n            os.makedirs(os.path.join(target_root, split, cls), exist_ok=True)\n\n    # \u5f00\u59cb\u5212\u5206\n    for cls in tqdm(classes, desc=\"\u6b63\u5728\u5212\u5206\u6570\u636e\u96c6\"):\n        cls_path = os.path.join(source_root, cls)\n        # \u83b7\u53d6\u8be5\u7c7b\u522b\u4e0b\u6240\u6709\u56fe\u7247\u6587\u4ef6\n        images = [f for f in os.listdir(cls_path) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n\n        # \u968f\u673a\u6253\u4e71\n        random.shuffle(images)\n\n        # \u8ba1\u7b97\u5207\u5206\u70b9\n        num_total = len(images)\n        num_train = int(num_total * split_ratio[0])\n        num_val = int(num_total * split_ratio[1])\n        # \u5269\u4e0b\u7684\u90fd\u7ed9\u6d4b\u8bd5\u96c6\uff0c\u907f\u514d\u56e0\u53d6\u6574\u4e22\u5931\u6570\u636e\n\n        train_imgs = images[:num_train]\n        val_imgs = images[num_train: num_train + num_val]\n        test_imgs = images[num_train + num_val:]\n\n        # \u590d\u5236\u6587\u4ef6\u51fd\u6570\n        def copy_files(file_list, split_name):\n            for file_name in file_list:\n                src = os.path.join(cls_path, file_name)\n                dst = os.path.join(target_root, split_name, cls, file_name)\n                shutil.copy(src, dst)\n\n        # \u6267\u884c\u590d\u5236\n        copy_files(train_imgs, 'train')\n        copy_files(val_imgs, 'val')\n        copy_files(test_imgs, 'test')\n\n        print(f\"\u7c7b\u522b [{cls}]: \u603b\u6570 {num_total} -&gt; Train:{len(train_imgs)} Val:{len(val_imgs)} Test:{len(test_imgs)}\")\n\n    print(f\"\\n[Done] \u6570\u636e\u96c6\u5212\u5206\u5b8c\u6210\uff01\u4fdd\u5b58\u5728: {target_root}\")\n\n\nif __name__ == \"__main__\":\n    split_dataset()\n</code></pre>", "tags": ["Python", "\u6570\u636e\u96c6"]}, {"location": "posts/example/", "title": "\u6587\u7ae0\u6807\u9898 (\u4f8b\u5982\uff1a\u57fa\u4e8e Huffman \u7f16\u7801\u7684\u6587\u4ef6\u538b\u7f29\u5668\u5f00\u53d1\u5fc3\u5f97)", "text": "<p>\u6458\u8981\uff1a\u8fd9\u91cc\u5199\u4e00\u4e24\u53e5\u7b80\u77ed\u7684\u4ecb\u7ecd\uff0c\u6bd4\u5982\u8fd9\u7bc7\u6587\u7ae0\u89e3\u51b3\u4e86\u4ec0\u4e48\u95ee\u9898\uff0c\u6216\u8005\u4f60\u5b66\u5230\u4e86\u4ec0\u4e48\u6838\u5fc3\u77e5\u8bc6\u3002</p>", "tags": ["Python", "\u7b97\u6cd5", "\u5b66\u4e60\u7b14\u8bb0"]}, {"location": "posts/example/#1", "title": "1. \u80cc\u666f\u4ecb\u7ecd", "text": "<p>\u5728\u6b64\u5904\u63cf\u8ff0\u4e3a\u4ec0\u4e48\u8981\u505a\u8fd9\u4e2a\u9879\u76ee\uff0c\u6216\u8005\u4e3a\u4ec0\u4e48\u8981\u5b66\u8fd9\u4e2a\u77e5\u8bc6\u70b9\u3002 \u4f8b\u5982\uff1a\u201c\u6700\u8fd1\u4e3a\u4e86\u51c6\u5907 C \u8bed\u8a00\u7f16\u7a0b\u6bd4\u8d5b\uff0c\u6211\u51b3\u5b9a\u6311\u6218\u5199\u4e00\u4e2a\u6587\u4ef6\u538b\u7f29\u5de5\u5177...\u201d</p>", "tags": ["Python", "\u7b97\u6cd5", "\u5b66\u4e60\u7b14\u8bb0"]}, {"location": "posts/example/#2", "title": "2. \u6838\u5fc3\u539f\u7406 (\u53ef\u4ee5\u4f7f\u7528\u516c\u5f0f\u4e86\uff01)", "text": "<p>\u8fd9\u91cc\u89e3\u91ca\u7406\u8bba\u90e8\u5206\u3002\u56e0\u4e3a\u6211\u4eec\u5f00\u542f\u4e86 MathJax\uff0c\u4f60\u53ef\u4ee5\u5c3d\u60c5\u5c55\u793a\u6570\u5b66\u4e4b\u7f8e\uff1a</p> <p>Huffman \u6811\u7684\u5e26\u6743\u8def\u5f84\u957f\u5ea6 (WPL) \u8ba1\u7b97\u516c\u5f0f\u4e3a\uff1a $\\(WPL = \\sum_{i=1}^{n} w_i l_i\\)$</p>", "tags": ["Python", "\u7b97\u6cd5", "\u5b66\u4e60\u7b14\u8bb0"]}, {"location": "posts/example/#3", "title": "3. \u4ee3\u7801\u5b9e\u73b0", "text": "<p>\u5c55\u793a\u4f60\u7684\u6838\u5fc3\u4ee3\u7801\uff0c\u8bb0\u5f97\u7528\u4e09\u4e2a\u53cd\u5f15\u53f7\u5305\u88f9\uff1a</p> <pre><code>// \u8fd9\u91cc\u7c98\u8d34\u4f60\u7684 C \u8bed\u8a00\u6216 Python \u4ee3\u7801\ntypedef struct {\n    int weight;\n    int parent, lchild, rchild;\n} HTNode, *HuffmanTree;\n</code></pre>", "tags": ["Python", "\u7b97\u6cd5", "\u5b66\u4e60\u7b14\u8bb0"]}]}