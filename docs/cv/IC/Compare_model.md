---
title: å¯¹æ¯”æ¨¡å‹æ€§èƒ½
date: 2026-01-17
tags:
  - Python
  - æ¨¡å‹æ€§èƒ½
---

# å¯¹æ¯”æ¨¡å‹æ€§èƒ½

## æ ¸å¿ƒä»£ç ï¼š

```python
import os
import time
import torch
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import timm
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from tqdm import tqdm
import re

# å°è¯•å¯¼å…¥ FLOPs è®¡ç®—å·¥å…· (å¦‚æœæ²¡æœ‰å®‰è£… thopï¼Œä¼šè‡ªåŠ¨è·³è¿‡)
try:
    from thop import profile
    HAS_THOP = True
except ImportError:
    HAS_THOP = False
    print("[æç¤º] æœªæ£€æµ‹åˆ° 'thop' åº“ï¼Œå°†è·³è¿‡ FLOPs è®¡ç®—ã€‚(å»ºè®®: pip install thop)")

# ==========================================
# 1. å…¨å±€é…ç½® [æ ¸å¿ƒä¿®æ”¹åŒº]
# ==========================================
class Config:
    # --- [å¿…å¡«] å¾…å¯¹æ¯”çš„æ¨¡å‹æ¸…å• ---
    # è¯·åœ¨ä¸‹æ–¹åˆ—è¡¨ä¸­å¡«å†™ä½ è¦PKçš„æ¨¡å‹ä¿¡æ¯
    # æ ¼å¼: {'name': 'è‡ªå®šä¹‰æ˜¾ç¤ºå', 'arch': 'æ¨¡å‹æ¶æ„å(å¦‚resnet50)', 'path': '.pthæƒé‡è·¯å¾„'}
    MY_MODELS = [
        {
            'name': 'ResNet50_Run1', 
            'arch': 'resnet50', 
            'path': './results/resnet50_run1/best_model.pth' 
        },
        {
            'name': 'ResNet50_Run2', 
            'arch': 'resnet50', 
            'path': './results/resnet50_run2/best_model.pth'
        },
        # {
        #     'name': 'MobileNetV3', 
        #     'arch': 'mobilenetv3_large_100', 
        #     'path': './results/mobilenet/best_model.pth'
        # }
    ]
    
    # --- [å¿…å¡«] æ•°æ®é›†è®¾ç½® ---
    USE_CUSTOM_DATASET = True        # [å¿…æ”¹] True=è‡ªå®šä¹‰æ–‡ä»¶å¤¹, False=å†…ç½®
    CUSTOM_DATA_ROOT = "./datasets/Intel Image Classification" # [å¿…æ”¹] æ•°æ®é›†è·¯å¾„
    BUILTIN_NAME = "CIFAR10"         # [å¯é€‰] å†…ç½®æ•°æ®é›†åç§°
    DATA_DOWNLOAD_ROOT = "./data"    # [å¯é€‰] æ•°æ®ç¼“å­˜è·¯å¾„
    
    # --- [å¿…å¡«] æ¨¡å‹å‚æ•° (éœ€ä¸è®­ç»ƒæ—¶ä¸€è‡´) ---
    NUM_CLASSES = 6                  # [å¿…æ”¹] ç±»åˆ«æ•°é‡ (Intel=6, Cassava=5)
    IMG_SIZE = 224                   # [å¿…æ”¹] å›¾ç‰‡è¾“å…¥å°ºå¯¸ (å½±å“é€Ÿåº¦å’ŒFLOPsè®¡ç®—)
    BATCH_SIZE = 32                  # [å¾®è°ƒ] æ‰¹æ¬¡å¤§å°
    
    # --- [å¯é€‰] ç¡¬ä»¶ä¸ä¿å­˜ ---
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    SAVE_DIR = "./benchmark_results" # ç»“æœä¿å­˜ç›®å½•

# ==========================================
# 2. æ ¸å¿ƒå·¥å…·å‡½æ•°
# ==========================================
def load_my_model(info):
    """åŠ è½½æœ¬åœ°è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡"""
    print(f"ğŸ”¹ æ­£åœ¨åŠ è½½: {info['name']} ({info['arch']})...")
    
    # 1. åˆ›å»ºæ¨¡å‹éª¨æ¶
    try:
        model = timm.create_model(info['arch'], pretrained=False, num_classes=Config.NUM_CLASSES)
    except Exception as e:
        print(f"   âŒ æ¶æ„å '{info['arch']}' é”™è¯¯æˆ–ä¸æ”¯æŒ: {e}")
        return None
    
    # 2. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(info['path']):
        print(f"   âŒ æ‰¾ä¸åˆ°æƒé‡æ–‡ä»¶: {info['path']}")
        return None
        
    # 3. åŠ è½½æƒé‡ (å…¼å®¹å¤„ç† state_dict)
    try:
        checkpoint = torch.load(info['path'], map_location=Config.DEVICE)
        # æœ‰äº›checkpointä¿å­˜æ•´ä¸ªdictï¼Œæœ‰äº›åªä¿å­˜æƒé‡ï¼Œè¿™é‡Œåšè‡ªé€‚åº”å¤„ç†
        state_dict = checkpoint['state_dict'] if isinstance(checkpoint, dict) and 'state_dict' in checkpoint else checkpoint
        model.load_state_dict(state_dict)
        
        model.to(Config.DEVICE)
        model.eval()
        return model
    except Exception as e:
        print(f"   âŒ æƒé‡åŠ è½½å¤±è´¥ (æ¶æ„ä¸åŒ¹é…?): {e}")
        return None

def get_model_size_mb(path):
    """è·å–æ¨¡å‹æ–‡ä»¶å¤§å° (MB)"""
    return os.path.getsize(path) / (1024 * 1024)

def get_params_count(model):
    """è®¡ç®—å‚æ•°é‡ (Million)"""
    return sum(p.numel() for p in model.parameters()) / 1e6

def get_flops(model):
    """è®¡ç®—è®¡ç®—é‡ (GFLOPs)"""
    if not HAS_THOP: return 0
    input = torch.randn(1, 3, Config.IMG_SIZE, Config.IMG_SIZE).to(Config.DEVICE)
    try:
        # thop åº“ç”¨äºè®¡ç®— FLOPs
        flops, params = profile(model, inputs=(input, ), verbose=False)
        return flops / 1e9
    except:
        return 0

def measure_speed(model, repetitions=50):
    """æµ‹è¯•æ¨ç†é€Ÿåº¦ (FPS & Latency)"""
    input = torch.randn(1, 3, Config.IMG_SIZE, Config.IMG_SIZE).to(Config.DEVICE)
    
    # é¢„çƒ­ GPU (æ¶ˆé™¤é¦–æ¬¡è¿è¡Œå¼€é”€)
    with torch.no_grad():
        for _ in range(10): model(input)
    
    # æ­£å¼è®¡æ—¶
    torch.cuda.synchronize() if torch.cuda.is_available() else None
    start = time.time()
    with torch.no_grad():
        for _ in range(repetitions): model(input)
    torch.cuda.synchronize() if torch.cuda.is_available() else None
    end = time.time()
    
    avg_latency = (end - start) / repetitions * 1000 # ms
    fps = 1000 / avg_latency
    return avg_latency, fps

def evaluate_accuracy(model, dataloader):
    """åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°å‡†ç¡®ç‡"""
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for imgs, labels in tqdm(dataloader, desc="   Eval", leave=False):
            imgs, labels = imgs.to(Config.DEVICE), labels.to(Config.DEVICE)
            outputs = model(imgs)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    return 100 * correct / total

def get_dataloader():
    """åŠ è½½æµ‹è¯•æ•°æ® (ä¼˜å…ˆä½¿ç”¨ test ç›®å½•ï¼Œæ²¡æœ‰åˆ™å¤ç”¨ val)"""
    tf = transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    if not Config.USE_CUSTOM_DATASET:
        # å†…ç½®æ•°æ®é›†é€»è¾‘
        try: DatasetClass = getattr(datasets, Config.BUILTIN_NAME)
        except: return None
        ds = DatasetClass(root=Config.DATA_DOWNLOAD_ROOT, train=False, download=True, transform=tf)
    else:
        # è‡ªå®šä¹‰æ•°æ®é›†é€»è¾‘
        test_path = os.path.join(Config.CUSTOM_DATA_ROOT, "test")
        val_path = os.path.join(Config.CUSTOM_DATA_ROOT, "val")
        
        if os.path.exists(test_path):
            print(f"[Data] ä½¿ç”¨æµ‹è¯•é›†: {test_path}")
            ds = datasets.ImageFolder(test_path, transform=tf)
        elif os.path.exists(val_path):
            print(f"[Data] æœªæ‰¾åˆ°ç‹¬ç«‹æµ‹è¯•é›†ï¼Œå¤ç”¨éªŒè¯é›†: {val_path}")
            ds = datasets.ImageFolder(val_path, transform=tf)
        else:
            print(f"âŒ é”™è¯¯: åœ¨ {Config.CUSTOM_DATA_ROOT} ä¸‹æœªæ‰¾åˆ°æ•°æ®")
            return None
            
    return DataLoader(ds, batch_size=Config.BATCH_SIZE, shuffle=False, num_workers=2)

def generate_safe_filename(models_list):
    """è‡ªåŠ¨ç”Ÿæˆå”¯ä¸€ä¸”åˆæ³•çš„æ–‡ä»¶å (åŸºäºæ¨¡å‹åç§°æ‹¼æ¥)"""
    names = [m['name'] for m in models_list]
    joined_name = "_vs_".join(names)
    # æ›¿æ¢éæ³•å­—ç¬¦å¹¶é™åˆ¶é•¿åº¦
    safe_name = re.sub(r'[\\/*?:"<>| ]', '_', joined_name)
    if len(safe_name) > 100: safe_name = safe_name[:100] + "_etc"
    return "Compare_" + safe_name

# ==========================================
# 3. ä¸»ç¨‹åºå…¥å£
# ==========================================
if __name__ == "__main__":
    os.makedirs(Config.SAVE_DIR, exist_ok=True)
    print(f"ğŸš€ å¼€å§‹å¯¹æ¯”æœ¬åœ°æ¨¡å‹ (å…± {len(Config.MY_MODELS)} ä¸ª)...")
    
    # 1. å‡†å¤‡æ•°æ®
    dataloader = get_dataloader()
    if dataloader is None: exit()
    
    results = []
    
    # 2. å¾ªç¯è¯„æµ‹æ¯ä¸ªæ¨¡å‹
    for info in Config.MY_MODELS:
        model = load_my_model(info)
        if model is None: continue
        
        # é‡‡é›†æŒ‡æ ‡
        params = get_params_count(model)
        size_mb = get_model_size_mb(info['path'])
        flops = get_flops(model)
        latency, fps = measure_speed(model)
        acc = evaluate_accuracy(model, dataloader)
        
        print(f"   âœ… Acc: {acc:.2f}% | FPS: {fps:.1f} | Params: {params:.2f}M")
        
        results.append({
            "Model": info['name'],
            "Accuracy (%)": acc,
            "Parameters (M)": params,
            "FLOPs (G)": flops,
            "Model Size (MB)": size_mb,
            "Inference Speed (FPS)": fps,
        })
        
    if not results:
        print("âŒ æœªäº§ç”Ÿä»»ä½•æœ‰æ•ˆç»“æœï¼Œè¯·æ£€æŸ¥æ¨¡å‹è·¯å¾„ã€‚")
        exit()
        
    # 3. ä¿å­˜ CSV æŠ¥å‘Š
    base_name = generate_safe_filename(Config.MY_MODELS)
    csv_path = os.path.join(Config.SAVE_DIR, base_name + ".csv")
    png_path = os.path.join(Config.SAVE_DIR, base_name + ".png")
    
    df = pd.DataFrame(results)
    print("\n" + "="*50)
    print(f"ğŸ† è¯¦ç»†æŠ¥å‘Šå·²ç”Ÿæˆ: {csv_path}")
    print("="*50)
    print(df.to_string(index=False))
    df.to_csv(csv_path, index=False)
    
    # 4. ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
    metrics = ["Accuracy (%)", "Parameters (M)", "FLOPs (G)", "Model Size (MB)", "Inference Speed (FPS)"]
    valid_metrics = metrics if HAS_THOP else [m for m in metrics if "FLOPs" not in m]

    plt.figure(figsize=(18, 10))
    for i, metric in enumerate(valid_metrics):
        rows = 2
        cols = (len(valid_metrics) + 1) // 2
        plt.subplot(rows, cols, i+1)
        
        # ç»˜åˆ¶æŸ±çŠ¶å›¾
        sns.barplot(x="Model", y=metric, data=df, palette="viridis")
        plt.title(metric, fontsize=14, fontweight='bold')
        plt.xticks(rotation=45)
        
        # åœ¨æŸ±å­ä¸Šæ ‡æ³¨å…·ä½“æ•°å€¼
        for index, row in df.iterrows():
             plt.text(index, row[metric], round(row[metric], 2), color='black', ha="center", va="bottom")
             
    plt.tight_layout()
    plt.savefig(png_path)
    print(f"\nğŸ“Š å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜: {png_path}")
```