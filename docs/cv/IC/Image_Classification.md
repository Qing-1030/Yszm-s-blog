---
title: å›¾åƒåˆ†ç±»æ¨¡å‹é€šç”¨æ¨¡æ¿
date: 2026-01-12
tags:
  - Python
  - è®¡ç®—æœºè§†è§‰
  - å›¾åƒåˆ†ç±»
---

# å›¾åƒåˆ†ç±»æ¨¡å‹é€šç”¨æ¨¡æ¿

> æ‘˜è¦ï¼šä¸€ä¸ªå¯é…ç½®çš„ä»£ç æ¨¡æ¿ï¼Œç”¨äºè®­ç»ƒå›¾åƒåˆ†ç±»æ¨¡å‹

## æ ¸å¿ƒä»£ç ï¼š

```python
import os
import sys
import time
import random
import logging
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
from torchvision import datasets, transforms
import timm
from timm.data import resolve_data_config
from tqdm import tqdm
import matplotlib.pyplot as plt

# å°è¯•å¯¼å…¥é«˜çº§è¯„ä¼°åº“
try:
    from sklearn.metrics import classification_report, confusion_matrix
    import seaborn as sns
    HAS_SKLEARN = True
except ImportError:
    HAS_SKLEARN = False
    print("[Warning] æœªå®‰è£… sklearn æˆ– seabornï¼Œå°†è·³è¿‡æ··æ·†çŸ©é˜µç»˜åˆ¶ã€‚")

# ==========================================
# 1. å…¨å±€é…ç½® [æ ¸å¿ƒä¿®æ”¹åŒº]
# ==========================================
class Config:
    # --- æ•°æ®é›†è·¯å¾„è®¾ç½® ---
    USE_CUSTOM_DATASET = True        # [å¿…æ”¹] True=ä½¿ç”¨è‡ªå®šä¹‰æ–‡ä»¶å¤¹, False=ä½¿ç”¨å†…ç½®(CIFAR10ç­‰)
    CUSTOM_DATA_ROOT = "flower_data" # [å¿…æ”¹] è‡ªå®šä¹‰æ•°æ®é›†æ ¹ç›®å½• (åŒ…å« train/val)
    BUILTIN_NAME = "CIFAR10"         # [å¯é€‰] å†…ç½®æ•°æ®é›†åç§° (ä»…å½“ä¸Šé¢ä¸ºFalseæ—¶ç”Ÿæ•ˆ)
    DATA_DOWNLOAD_ROOT = "./data"    # [å¯é€‰] æ•°æ®ä¸‹è½½ç¼“å­˜è·¯å¾„
    
    # --- ç»“æœä¿å­˜è®¾ç½® ---
    SAVE_DIR_ROOT = "./results"      # [å¯é€‰] è®­ç»ƒç»“æœä¿å­˜æ ¹ç›®å½•
    SAVE_DIR = ""                    # (ç¨‹åºè‡ªåŠ¨ç”Ÿæˆï¼Œæ— éœ€ä¿®æ”¹)
    
    # --- æ¨¡å‹ä¸è®­ç»ƒè®¾ç½® ---
    MODEL_NAME = "resnet50"          # [å¯é€‰] æ¨¡å‹åç§° (å¦‚ resnet50, efficientnet_b0)
    CHECKPOINT_PATH = ""             # [å¯é€‰] é¢„è®­ç»ƒæƒé‡è·¯å¾„ (ç©ºåˆ™ä¸‹è½½ImageNetæƒé‡)
    RESUME_PATH = ""                 # [å¯é€‰] æ–­ç‚¹ç»­è®­çš„ .pth æ–‡ä»¶è·¯å¾„
    NUM_CLASSES = 0                  # (ç¨‹åºè‡ªåŠ¨è¯†åˆ«ï¼Œæ— éœ€ä¿®æ”¹)
    
    # --- è¶…å‚æ•°è®¾ç½® ---
    BATCH_SIZE = 32                  # [å¾®è°ƒ] æ‰¹æ¬¡å¤§å° (æ˜¾å­˜ä¸è¶³æ”¹å°)
    EPOCHS = 50                      # [å¾®è°ƒ] è®­ç»ƒè½®æ•°
    LR = 1e-4                        # [å¾®è°ƒ] åˆå§‹å­¦ä¹ ç‡ (å¾®è°ƒé€šå¸¸ç”¨ 1e-4 æˆ– 1e-5)
    WEIGHT_DECAY = 1e-4              # [å¾®è°ƒ] æ­£åˆ™åŒ–ç³»æ•° (æŠ—è¿‡æ‹Ÿåˆç”¨)
    SEED = 42                        # [å¯é€‰] éšæœºç§å­ (ä¿è¯ç»“æœå¯å¤ç°)
    
    # --- ä¼˜åŒ–ç­–ç•¥ ---
    OPTIMIZER_NAME = 'adamw'         # [å¯é€‰] ä¼˜åŒ–å™¨: 'adamw', 'adam', 'sgd'
    SCHEDULER_NAME = 'plateau'       # [å¯é€‰] å­¦ä¹ ç‡ç­–ç•¥: 'plateau'(ç›‘æ§), 'cosine'(ä½™å¼¦), 'step'
    
    # --- æ—©åœ (Early Stopping) ---
    EARLY_STOP_PATIENCE = 7          # [å¯é€‰] è¿ç»­å¤šå°‘è½®ä¸æ¶¨åˆ†å°±åœæ­¢ (0è¡¨ç¤ºå…³é—­)
    
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ==========================================
# 2. è¾…åŠ©å·¥å…· (æ—¥å¿—/éšæœºç§å­/æ—©åœ)
# ==========================================
def setup_logger(save_dir):
    """é…ç½®æ—¥å¿—ç³»ç»Ÿï¼šåŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶"""
    log_format = '%(asctime)s - %(message)s'
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    
    # æ–‡ä»¶æ—¥å¿— (UTF-8ç¼–ç )
    file_handler = logging.FileHandler(os.path.join(save_dir, "train.log"), encoding='utf-8')
    file_handler.setFormatter(logging.Formatter(log_format))
    logger.addHandler(file_handler)
    
    # æ§åˆ¶å°æ—¥å¿—
    stream_handler = logging.StreamHandler(sys.stdout)
    stream_handler.setFormatter(logging.Formatter(log_format))
    logger.addHandler(stream_handler)
    return logger

def seed_everything(seed):
    """å›ºå®šæ‰€æœ‰éšæœºç§å­ä»¥ä¿è¯å®éªŒå¯å¤ç°"""
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True

class EarlyStopping:
    """æ—©åœæ§åˆ¶å™¨ï¼šå½“éªŒè¯é›†å‡†ç¡®ç‡ä¸å†æå‡æ—¶æå‰ç»ˆæ­¢è®­ç»ƒ"""
    def __init__(self, patience=7, delta=0):
        self.patience = patience
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.delta = delta

    def __call__(self, val_acc):
        if not self.patience or self.patience <= 0: return
        
        # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡è®°å½•
        if self.best_score is None:
            self.best_score = val_acc
        # å¦‚æœå½“å‰åˆ†æ•°æ²¡æœ‰æ˜æ˜¾æå‡
        elif val_acc < self.best_score + self.delta:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
        # å¦‚æœæœ‰æå‡ï¼Œé‡ç½®è®¡æ•°å™¨
        else:
            self.best_score = val_acc
            self.counter = 0

def get_optimizer(model):
    """æ ¹æ®é…ç½®åˆ›å»ºä¼˜åŒ–å™¨"""
    name = Config.OPTIMIZER_NAME.lower()
    p = model.parameters()
    if name == 'adamw': return optim.AdamW(p, lr=Config.LR, weight_decay=Config.WEIGHT_DECAY)
    elif name == 'sgd': return optim.SGD(p, lr=Config.LR, momentum=0.9, weight_decay=Config.WEIGHT_DECAY)
    else: return optim.Adam(p, lr=Config.LR, weight_decay=Config.WEIGHT_DECAY)

def get_scheduler(optimizer):
    """æ ¹æ®é…ç½®åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨"""
    name = Config.SCHEDULER_NAME.lower()
    if name == 'plateau': return optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)
    elif name == 'cosine': return optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=Config.EPOCHS, eta_min=1e-6)
    elif name == 'step': return optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)
    return None

# ==========================================
# 3. æ•°æ®åŠ è½½ä¸å¤„ç†
# ==========================================
def get_transforms(model_cfg):
    """æ ¹æ®æ¨¡å‹é»˜è®¤å‚æ•°è‡ªåŠ¨ç”Ÿæˆé¢„å¤„ç†ç®¡çº¿"""
    input_size = model_cfg.get('input_size', (3, 224, 224))
    crop_size = input_size[1]
    mean = model_cfg.get('mean', [0.485, 0.456, 0.406])
    std = model_cfg.get('std', [0.229, 0.224, 0.225])
    
    # è®­ç»ƒé›†å¢å¼ºï¼šéšæœºè£å‰ªã€ç¿»è½¬ã€æ—‹è½¬ã€é¢œè‰²æŠ–åŠ¨
    train_tf = transforms.Compose([
        transforms.Resize((crop_size, crop_size)),
        transforms.RandomHorizontalFlip(0.5),
        transforms.RandomRotation(15),
        transforms.ColorJitter(0.1, 0.1, 0.1),
        transforms.ToTensor(),
        transforms.Normalize(mean, std)
    ])
    # éªŒè¯é›†å¤„ç†ï¼šä»…è°ƒæ•´å¤§å°å’Œå½’ä¸€åŒ–
    val_tf = transforms.Compose([
        transforms.Resize((crop_size, crop_size)),
        transforms.ToTensor(),
        transforms.Normalize(mean, std)
    ])
    return train_tf, val_tf

def get_dataloaders(train_tf, val_tf, logger):
    """
    æ™ºèƒ½åŠ è½½æ•°æ®é›†
    ä¼˜åŒ–ç‚¹ï¼šå¦‚æœè‡ªå®šä¹‰æ•°æ®é›†ä¸­æ²¡æœ‰ test ç›®å½•ï¼Œè‡ªåŠ¨å¤ç”¨ val é›†ä½œä¸ºæµ‹è¯•é›†ï¼Œ
    ä¿è¯åç»­è¯„ä¼°ä»£ç ä¸æŠ¥é”™ã€‚
    """
    # --- åˆ†æ”¯1: å†…ç½®æ•°æ®é›† (CIFAR10ç­‰) ---
    if not Config.USE_CUSTOM_DATASET:
        logger.info(f"[Data] åŠ è½½å†…ç½®æ•°æ®é›†: {Config.BUILTIN_NAME}")
        try: DatasetClass = getattr(datasets, Config.BUILTIN_NAME)
        except AttributeError: raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®é›†: {Config.BUILTIN_NAME}")
        
        full_ds = DatasetClass(root=Config.DATA_DOWNLOAD_ROOT, train=True, download=True, transform=train_tf)
        test_ds = DatasetClass(root=Config.DATA_DOWNLOAD_ROOT, train=False, download=True, transform=val_tf)
        
        # åˆ’åˆ† 90% è®­ç»ƒ, 10% éªŒè¯
        train_sz = int(0.9 * len(full_ds))
        train_ds, val_ds = random_split(full_ds, [train_sz, len(full_ds)-train_sz])
        class_names = full_ds.classes

    # --- åˆ†æ”¯2: è‡ªå®šä¹‰æ–‡ä»¶å¤¹æ•°æ®é›† ---
    else:
        logger.info(f"[Data] åŠ è½½è‡ªå®šä¹‰æ–‡ä»¶å¤¹: {Config.CUSTOM_DATA_ROOT}")
        train_dir = os.path.join(Config.CUSTOM_DATA_ROOT, "train")
        val_dir = os.path.join(Config.CUSTOM_DATA_ROOT, "val")
        test_dir = os.path.join(Config.CUSTOM_DATA_ROOT, "test")
        
        if not os.path.exists(train_dir): raise FileNotFoundError(f"ç¼ºå¤±ç›®å½•: {train_dir}")
        train_ds = datasets.ImageFolder(train_dir, transform=train_tf)
        val_ds = datasets.ImageFolder(val_dir, transform=val_tf)
        
        # [é€»è¾‘ä¼˜åŒ–] æ£€æŸ¥æµ‹è¯•é›†æ˜¯å¦å­˜åœ¨
        if os.path.exists(test_dir):
            logger.info("[Data] å‘ç°ç‹¬ç«‹æµ‹è¯•é›† test/")
            test_ds = datasets.ImageFolder(test_dir, transform=val_tf)
        else:
            logger.info("[Data] æœªå‘ç°ç‹¬ç«‹æµ‹è¯•é›†ï¼Œå°†å¤ç”¨éªŒè¯é›†(val)è¿›è¡Œæœ€ç»ˆè¯„ä¼°")
            test_ds = val_ds 
            
        class_names = train_ds.classes

    # æ›´æ–°å…¨å±€é…ç½®
    Config.NUM_CLASSES = len(class_names)
    logger.info(f"[Data] ç±»åˆ«æ•°: {Config.NUM_CLASSES}")
    
    # åˆ›å»ºDataLoader
    train_dl = DataLoader(train_ds, batch_size=Config.BATCH_SIZE, shuffle=True, num_workers=4)
    val_dl = DataLoader(val_ds, batch_size=Config.BATCH_SIZE, shuffle=False, num_workers=4)
    test_dl = DataLoader(test_ds, batch_size=Config.BATCH_SIZE, shuffle=False, num_workers=4)
    
    return train_dl, val_dl, test_dl, class_names

# ==========================================
# 4. è®­ç»ƒä¸éªŒè¯é€»è¾‘
# ==========================================
def train_one_epoch(model, loader, criterion, optimizer, epoch):
    """è®­ç»ƒä¸€ä¸ª Epoch"""
    model.train()
    total_loss, total_correct = 0.0, 0
    bar = tqdm(loader, desc=f"Epoch {epoch}/{Config.EPOCHS} [Train]", leave=False)
    
    for imgs, labels in bar:
        imgs, labels = imgs.to(Config.DEVICE), labels.to(Config.DEVICE)
        
        optimizer.zero_grad()
        outputs = model(imgs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item() * imgs.size(0)
        total_correct += (outputs.argmax(1) == labels).sum().item()
        bar.set_postfix(loss=loss.item(), lr=optimizer.param_groups[0]['lr'])
        
    return total_loss / len(loader.dataset), total_correct / len(loader.dataset)

@torch.no_grad()
def validate(model, loader, criterion, epoch, phase="Val"):
    """éªŒè¯æ¨¡å‹æ€§èƒ½"""
    model.eval()
    total_loss, total_correct = 0.0, 0
    bar = tqdm(loader, desc=f"Epoch {epoch}/{Config.EPOCHS} [{phase}]  ", leave=False)
    
    for imgs, labels in bar:
        imgs, labels = imgs.to(Config.DEVICE), labels.to(Config.DEVICE)
        outputs = model(imgs)
        loss = criterion(outputs, labels)
            
        total_loss += loss.item() * imgs.size(0)
        total_correct += (outputs.argmax(1) == labels).sum().item()
        bar.set_postfix(loss=loss.item())
        
    return total_loss / len(loader.dataset), total_correct / len(loader.dataset)

def evaluate_test_set(model, loader, class_names, logger):
    """è®­ç»ƒç»“æŸåè¯„ä¼°å¹¶åœ¨æ—¥å¿—ä¸­ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
    if not loader or not HAS_SKLEARN: return
    logger.info("[Test] æ‰§è¡Œæœ€ç»ˆè¯„ä¼°...")
    model.eval()
    preds, targets = [], []
    
    with torch.no_grad():
        for imgs, labels in tqdm(loader, desc="Testing"):
            imgs, labels = imgs.to(Config.DEVICE), labels.to(Config.DEVICE)
            outputs = model(imgs)
            preds.extend(outputs.argmax(1).cpu().numpy())
            targets.extend(labels.cpu().numpy())
    
    # æ‰“å°åˆ†ç±»æŠ¥å‘Š
    report = classification_report(targets, preds, target_names=class_names, digits=4)
    logger.info("\n" + report)
    
    # ç»˜åˆ¶å¹¶ä¿å­˜æ··æ·†çŸ©é˜µ
    plt.figure(figsize=(10, 8))
    sns.heatmap(confusion_matrix(targets, preds), annot=True, fmt='d', cmap='Blues', 
                xticklabels=class_names, yticklabels=class_names)
    plt.title('Confusion Matrix')
    plt.savefig(os.path.join(Config.SAVE_DIR, 'confusion_matrix.png'))
    logger.info("[Info] æ··æ·†çŸ©é˜µå·²ä¿å­˜")

def plot_history(h, save_dir, logger):
    """ç»˜åˆ¶è®­ç»ƒæ›²çº¿å›¾"""
    epochs = range(1, len(h['train_acc']) + 1)
    plt.figure(figsize=(12, 5))
    
    # å‡†ç¡®ç‡æ›²çº¿
    plt.subplot(1, 2, 1)
    plt.plot(epochs, h['train_acc'], label='Train')
    plt.plot(epochs, h['val_acc'], label='Val')
    plt.legend(); plt.title('Accuracy')
    
    # Lossæ›²çº¿
    plt.subplot(1, 2, 2)
    plt.plot(epochs, h['train_loss'], label='Train')
    plt.plot(epochs, h['val_loss'], label='Val')
    plt.legend(); plt.title('Loss')
    
    plt.savefig(os.path.join(save_dir, 'training_curve.png'))
    logger.info("[Info] è®­ç»ƒæ›²çº¿å·²ä¿å­˜")

def save_checkpoint(state, is_best, filename='last.pth'):
    """ä¿å­˜æ¨¡å‹æƒé‡"""
    path = os.path.join(Config.SAVE_DIR, filename)
    torch.save(state, path)
    if is_best: torch.save(state, os.path.join(Config.SAVE_DIR, 'best_model.pth'))

# ==========================================
# 5. ä¸»ç¨‹åºå…¥å£
# ==========================================
if __name__ == "__main__":
    seed_everything(Config.SEED)
    
    # 1. åˆå§‹åŒ–ä¿å­˜ç›®å½• (æ ¼å¼: æ¨¡å‹å_æ•°æ®é›†å_æ—¶é—´)
    if Config.RESUME_PATH:
        Config.SAVE_DIR = os.path.dirname(Config.RESUME_PATH)
    else:
        if Config.USE_CUSTOM_DATASET:
            ds_name = os.path.basename(Config.CUSTOM_DATA_ROOT)
        else:
            ds_name = Config.BUILTIN_NAME
        run_name = f"{Config.MODEL_NAME}_{ds_name}_{time.strftime('%Y%m%d_%H%M%S')}"
        Config.SAVE_DIR = os.path.join(Config.SAVE_DIR_ROOT, run_name)
        os.makedirs(Config.SAVE_DIR, exist_ok=True)
    
    logger = setup_logger(Config.SAVE_DIR)
    logger.info(f"[Config] ä¿å­˜ç›®å½•: {Config.SAVE_DIR}")
    
    # 2. å‡†å¤‡æ•°æ®
    tmp_model = timm.create_model(Config.MODEL_NAME, pretrained=True)
    cfg = resolve_data_config({}, model=tmp_model)
    del tmp_model # æ¸…ç†ä¸´æ—¶æ¨¡å‹
    
    train_tf, val_tf = get_transforms(cfg)
    train_dl, val_dl, test_dl, class_names = get_dataloaders(train_tf, val_tf, logger)
    logger.info(f"[Data] ç±»åˆ«åˆ—è¡¨: {class_names}")
    
    # 3. åˆå§‹åŒ–æ¨¡å‹
    logger.info(f"[Init] åˆ›å»ºæ¨¡å‹: {Config.MODEL_NAME}")
    if not Config.RESUME_PATH and Config.CHECKPOINT_PATH and os.path.exists(Config.CHECKPOINT_PATH):
        logger.info(f"[Load] åŠ è½½æœ¬åœ°é¢„è®­ç»ƒæƒé‡: {Config.CHECKPOINT_PATH}")
        model = timm.create_model(Config.MODEL_NAME, pretrained=False, num_classes=Config.NUM_CLASSES, checkpoint_path=Config.CHECKPOINT_PATH)
    else:
        model = timm.create_model(Config.MODEL_NAME, pretrained=True, num_classes=Config.NUM_CLASSES)
        
    model.to(Config.DEVICE)
    
    # 4. ä¼˜åŒ–å™¨ä¸è°ƒåº¦å™¨
    logger.info(f"[Init] Opt: {Config.OPTIMIZER_NAME}, Sch: {Config.SCHEDULER_NAME}")
    optimizer = get_optimizer(model)
    scheduler = get_scheduler(optimizer)
    criterion = nn.CrossEntropyLoss() # å¦‚éœ€æ ‡ç­¾å¹³æ»‘å¯æ”¹ä¸º nn.CrossEntropyLoss(label_smoothing=0.1)
    
    # åˆå§‹åŒ–æ—©åœ
    early_stop = None
    if Config.EARLY_STOP_PATIENCE and Config.EARLY_STOP_PATIENCE > 0:
        logger.info(f"[Init] æ—©åœå¼€å¯ (Patience={Config.EARLY_STOP_PATIENCE})")
        early_stop = EarlyStopping(patience=Config.EARLY_STOP_PATIENCE)
    
    # 5. è®­ç»ƒå¾ªç¯
    start_epoch = 1
    best_acc = 0.0
    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}
    
    # æ–­ç‚¹æ¢å¤é€»è¾‘
    if Config.RESUME_PATH and os.path.exists(Config.RESUME_PATH):
        logger.info(f"[Resume] æ¢å¤æ–­ç‚¹: {Config.RESUME_PATH}")
        ckpt = torch.load(Config.RESUME_PATH, map_location=Config.DEVICE)
        model.load_state_dict(ckpt['state_dict'])
        optimizer.load_state_dict(ckpt['optimizer'])
        if scheduler and 'scheduler' in ckpt: scheduler.load_state_dict(ckpt['scheduler'])
        start_epoch = ckpt['epoch'] + 1
        best_acc = ckpt['best_acc']
        history = ckpt['history']
    
    logger.info("[Start] å¼€å§‹è®­ç»ƒ...")
    for epoch in range(start_epoch, Config.EPOCHS + 1):
        t_loss, t_acc = train_one_epoch(model, train_dl, criterion, optimizer, epoch)
        v_loss, v_acc = validate(model, val_dl, criterion, epoch)
        
        # è®°å½•å†å²
        history['train_loss'].append(t_loss); history['train_acc'].append(t_acc)
        history['val_loss'].append(v_loss); history['val_acc'].append(v_acc)
        
        logger.info(f"Epoch {epoch}: Train Acc: {t_acc:.4f} | Val Acc: {v_acc:.4f} | Loss: {t_loss:.4f}")
        
        # æ›´æ–°å­¦ä¹ ç‡
        if scheduler:
            if Config.SCHEDULER_NAME == 'plateau': scheduler.step(v_acc)
            else: scheduler.step()
            
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        is_best = v_acc > best_acc
        if is_best:
            best_acc = v_acc
            logger.info(f" -> ğŸŒŸ æ–°çš„æœ€ä½³æ¨¡å‹ (Acc: {best_acc:.4f})")
            
        save_checkpoint({
            'epoch': epoch,
            'state_dict': model.state_dict(),
            'best_acc': best_acc,
            'optimizer': optimizer.state_dict(),
            'scheduler': scheduler.state_dict() if scheduler else None,
            'history': history
        }, is_best)
        
        # æ—©åœæ£€æµ‹
        if early_stop:
            early_stop(v_acc)
            if early_stop.early_stop:
                logger.info("[Stop] è§¦å‘æ—©åœ")
                break
                
    # 6. ç»“æŸè¯„ä¼°
    plot_history(history, Config.SAVE_DIR, logger)
    if test_dl:
        # åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæœ€ç»ˆæµ‹è¯•
        best_path = os.path.join(Config.SAVE_DIR, "best_model.pth")
        if os.path.exists(best_path):
            ckpt = torch.load(best_path, map_location=Config.DEVICE)
            model.load_state_dict(ckpt['state_dict'])
        evaluate_test_set(model, test_dl, class_names, logger)
        
    logger.info("[Done] å®Œæˆ")
```