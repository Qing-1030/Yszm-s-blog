---
title: å›¾åƒåˆ†ç±»æ¨¡å‹é€šç”¨æ¨¡æ¿
date: 2026-01-12
tags:
  - Python
  - è®¡ç®—æœºè§†è§‰
  - å›¾åƒåˆ†ç±»
---

# å›¾åƒåˆ†ç±»æ¨¡å‹é€šç”¨æ¨¡æ¿

> æ‘˜è¦ï¼šä¸€ä¸ªå¯é…ç½®çš„ä»£ç æ¨¡æ¿ï¼Œç”¨äºè®­ç»ƒå›¾åƒåˆ†ç±»æ¨¡å‹

## æ ¸å¿ƒä»£ç ï¼š

```python
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import timm
from timm.data import resolve_data_config
from tqdm import tqdm
import matplotlib.pyplot as plt

# å°è¯•å¯¼å…¥é«˜çº§è¯„ä¼°ç»˜å›¾åº“ï¼Œå¦‚æœæ²¡å®‰è£…åˆ™è·³è¿‡
try:
    from sklearn.metrics import classification_report, confusion_matrix
    import seaborn as sns

    HAS_SKLEARN = True
except ImportError:
    HAS_SKLEARN = False
    print("[Warning] æœªå®‰è£… scikit-learn æˆ– seabornï¼Œå°†è·³è¿‡æ··æ·†çŸ©é˜µç»˜åˆ¶ã€‚å»ºè®®å®‰è£…: pip install scikit-learn seaborn")


# ==========================================
# 1. é…ç½®åŒºåŸŸ [å¯å¾®è°ƒ]
# ==========================================
class Config:
    # è·¯å¾„è®¾ç½®
    data_root = "flower_data"  # <--- [å¯ä¿®æ”¹] æ•°æ®é›†æ ¹ç›®å½• (éœ€åŒ…å« train/val/test æ–‡ä»¶å¤¹)
    save_dir = "./results"  # <--- [å¯ä¿®æ”¹] ç»“æœä¿å­˜è·¯å¾„

    # æ¨¡å‹è®¾ç½®
    model_name = "resnet50"  # <--- [å¯å¾®è°ƒ] æ¨¡å‹åç§° (å¦‚ resnet18, efficientnet_b0, mobilenetv3_large_100)
    num_classes = 5  # <--- [å¯ä¿®æ”¹] åˆ†ç±»ç±»åˆ«æ•°
    pretrained = True  # <--- [å¯å¾®è°ƒ] æ˜¯å¦ä½¿ç”¨åœ¨çº¿é¢„è®­ç»ƒæƒé‡
    checkpoint_path = ""  # <--- [å¯å¾®è°ƒ] æœ¬åœ°æƒé‡è·¯å¾„ (ä»…å½“ pretrained=False æ—¶ä½¿ç”¨)

    # è®­ç»ƒè¶…å‚æ•°
    batch_size = 32  # <--- [å¯å¾®è°ƒ] æ‰¹æ¬¡å¤§å°
    epochs = 20  # <--- [å¯å¾®è°ƒ] è®­ç»ƒè½®æ•°
    lr = 1e-4  # <--- [å¯å¾®è°ƒ] å­¦ä¹ ç‡
    weight_decay = 1e-4  # <--- [å¯å¾®è°ƒ] æƒé‡è¡°å‡ (L2æ­£åˆ™åŒ–)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


# ==========================================
# 2. å‡†å¤‡å·¥ä½œï¼šæ¨¡å‹ä¸æ•°æ®
# ==========================================
def get_model_and_transforms():
    # 1. åˆ›å»ºæ¨¡å‹
    model = timm.create_model(
        Config.model_name,
        pretrained=Config.pretrained,
        checkpoint_path=Config.checkpoint_path,
        num_classes=Config.num_classes
    )
    model.to(Config.device)

    # 2. è·å–é»˜è®¤é…ç½®å¹¶æ‰“å°
    config = resolve_data_config({}, model=model)
    # print(f"[Info] Model Config: {config}")

    # 3. å®šä¹‰æ•°æ®å¢å¼º [å¯å¾®è°ƒ]
    # è®­ç»ƒé›†ï¼šéœ€è¦å¢å¼º
    train_transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.CenterCrop(224),  # æˆ–ä½¿ç”¨ RandomResizedCrop(224)
        transforms.RandomHorizontalFlip(0.5),
        transforms.RandomRotation(15),  # éšæœºæ—‹è½¬
        transforms.ColorJitter(brightness=0.1, contrast=0.1),  # é¢œè‰²æŠ–åŠ¨
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    # éªŒè¯é›†/æµ‹è¯•é›†ï¼šä¸éœ€è¦å¢å¼ºï¼Œåªéœ€è¦æ ‡å‡†åŒ–
    val_test_transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    return model, train_transform, val_test_transform


# ==========================================
# 3. æ ¸å¿ƒåŠŸèƒ½ï¼šè®­ç»ƒã€éªŒè¯ã€æµ‹è¯•
# ==========================================
def train_one_epoch(model, loader, criterion, optimizer, epoch):
    model.train()
    total_loss, total_correct = 0.0, 0

    bar = tqdm(loader, desc=f"Epoch {epoch}/{Config.epochs} [Train]")
    for imgs, labels in bar:
        imgs, labels = imgs.to(Config.device), labels.to(Config.device)

        optimizer.zero_grad()
        outputs = model(imgs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        total_loss += loss.item() * imgs.size(0)
        total_correct += (outputs.argmax(1) == labels).sum().item()

        bar.set_postfix(loss=loss.item())

    return total_loss / len(loader.dataset), total_correct / len(loader.dataset)


@torch.no_grad()
def validate(model, loader, criterion, epoch, phase="Val"):
    model.eval()
    total_loss, total_correct = 0.0, 0

    bar = tqdm(loader, desc=f"Epoch {epoch}/{Config.epochs} [{phase}]  ")
    for imgs, labels in bar:
        imgs, labels = imgs.to(Config.device), labels.to(Config.device)
        outputs = model(imgs)
        loss = criterion(outputs, labels)

        total_loss += loss.item() * imgs.size(0)
        total_correct += (outputs.argmax(1) == labels).sum().item()
        bar.set_postfix(loss=loss.item())

    return total_loss / len(loader.dataset), total_correct / len(loader.dataset)


def evaluate_test_set(model, test_loader, class_names):
    """
    ç‹¬ç«‹æµ‹è¯•å‡½æ•°ï¼šè¾“å‡ºåˆ†ç±»æŠ¥å‘Šå’Œæ··æ·†çŸ©é˜µ
    """
    if not HAS_SKLEARN:
        print("[Info] è·³è¿‡è¯¦ç»†æµ‹è¯•æŠ¥å‘Šï¼ˆç¼ºå°‘sklearnåº“ï¼‰")
        return

    model.eval()
    all_preds = []
    all_labels = []

    print(f"\n[Test] æ­£åœ¨è¿›è¡Œæœ€ç»ˆæµ‹è¯•é›†è¯„ä¼°...")
    with torch.no_grad():
        for imgs, labels in tqdm(test_loader, desc="Testing"):
            imgs = imgs.to(Config.device)
            labels = labels.to(Config.device)
            outputs = model(imgs)
            preds = outputs.argmax(dim=1)

            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    # 1. æ‰“å°åˆ†ç±»æŠ¥å‘Š (Precision, Recall, F1)
    print("\n" + "=" * 50)
    print("FINAL TEST REPORT")
    print("=" * 50)
    print(classification_report(all_labels, all_preds, target_names=class_names, digits=4))

    # 2. ç»˜åˆ¶æ··æ·†çŸ©é˜µ
    plt.figure(figsize=(10, 8))
    cm = confusion_matrix(all_labels, all_preds)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names)
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.title('Confusion Matrix')
    save_path = os.path.join(Config.save_dir, 'confusion_matrix.png')
    plt.savefig(save_path)
    print(f"[Info] æ··æ·†çŸ©é˜µå·²ä¿å­˜è‡³: {save_path}")
    # plt.show()


# ==========================================
# 4. è¾…åŠ©åŠŸèƒ½ï¼šç”»å›¾
# ==========================================
def plot_history(history, save_dir):
    epochs = range(1, len(history['train_acc']) + 1)

    plt.figure(figsize=(12, 5))

    # Accuracy Curve
    plt.subplot(1, 2, 1)
    plt.plot(epochs, history['train_acc'], 'b-o', label='Train Acc')
    plt.plot(epochs, history['val_acc'], 'r-o', label='Val Acc')
    plt.title('Training and Validation Accuracy')
    plt.legend()

    # Loss Curve
    plt.subplot(1, 2, 2)
    plt.plot(epochs, history['train_loss'], 'b-o', label='Train Loss')
    plt.plot(epochs, history['val_loss'], 'r-o', label='Val Loss')
    plt.title('Training and Validation Loss')
    plt.legend()

    plt.tight_layout()
    plt.savefig(os.path.join(save_dir, 'training_curve.png'))
    print(f"[Info] è®­ç»ƒæ›²çº¿å·²ä¿å­˜è‡³: {os.path.join(save_dir, 'training_curve.png')}")


# ==========================================
# 5. ä¸»ç¨‹åºå…¥å£
# ==========================================
if __name__ == "__main__":
    # åˆå§‹åŒ–
    os.makedirs(Config.save_dir, exist_ok=True)
    model, train_tf, val_test_tf = get_model_and_transforms()

    # åŠ è½½æ•°æ®é›†
    # å‡è®¾ç›®å½•ç»“æ„ä¸º: data_root/train, data_root/val, data_root/test
    train_ds = datasets.ImageFolder(os.path.join(Config.data_root, "train"), transform=train_tf)
    val_ds = datasets.ImageFolder(os.path.join(Config.data_root, "val"), transform=val_test_tf)

    train_loader = DataLoader(train_ds, batch_size=Config.batch_size, shuffle=True, num_workers=4)
    val_loader = DataLoader(val_ds, batch_size=Config.batch_size, shuffle=False, num_workers=4)

    print(f"[Data] Train: {len(train_ds)} | Val: {len(val_ds)}")

    # å®šä¹‰ä¼˜åŒ–å™¨ä¸æŸå¤±
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.lr, weight_decay=Config.weight_decay)

    # ---------------------------
    # Phase 1: è®­ç»ƒå¾ªç¯
    # ---------------------------
    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}
    best_acc = 0.0

    print(f"\n[Start] å¼€å§‹è®­ç»ƒ... (Total Epochs: {Config.epochs})")
    for epoch in range(1, Config.epochs + 1):
        t_loss, t_acc = train_one_epoch(model, train_loader, criterion, optimizer, epoch)
        v_loss, v_acc = validate(model, val_loader, criterion, epoch, phase="Val")

        history['train_loss'].append(t_loss)
        history['train_acc'].append(t_acc)
        history['val_loss'].append(v_loss)
        history['val_acc'].append(v_acc)

        print(f"Epoch {epoch}: Train Acc: {t_acc:.4f} | Val Acc: {v_acc:.4f}")

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if v_acc > best_acc:
            best_acc = v_acc
            torch.save(model.state_dict(), os.path.join(Config.save_dir, "best_model.pth"))
            print(f" -> ğŸŒŸ æœ€ä½³æ¨¡å‹å·²æ›´æ–° (Acc: {best_acc:.4f})")

    # ç»˜åˆ¶æ›²çº¿
    plot_history(history, Config.save_dir)

    # ---------------------------
    # Phase 2: æµ‹è¯•é›†è¯„ä¼°
    # ---------------------------
    print("\n" + "=" * 30)
    print("è¿›å…¥æµ‹è¯•é˜¶æ®µ (Test Phase)")
    print("=" * 30)

    # 1. åŠ è½½æµ‹è¯•æ•°æ® (æ³¨æ„ä½¿ç”¨ val_test_tfï¼Œä¸åšå¢å¼º)
    test_dir = os.path.join(Config.data_root, "test")
    if os.path.exists(test_dir):
        test_ds = datasets.ImageFolder(test_dir, transform=val_test_tf)
        test_loader = DataLoader(test_ds, batch_size=Config.batch_size, shuffle=False, num_workers=4)

        # 2. å¿…é¡»é‡æ–°åŠ è½½æœ€ä½³æƒé‡ (Best Weights)
        best_path = os.path.join(Config.save_dir, "best_model.pth")
        model.load_state_dict(torch.load(best_path))
        print(f"[Info] å·²åŠ è½½æœ€ä½³æƒé‡ç”¨äºæµ‹è¯•: {best_path}")

        # 3. æ‰§è¡Œè¯¦ç»†è¯„ä¼°
        evaluate_test_set(model, test_loader, train_ds.classes)

    else:
        print(f"[Warning] æœªæ‰¾åˆ°æµ‹è¯•é›†æ–‡ä»¶å¤¹ {test_dir}ï¼Œè·³è¿‡æµ‹è¯•æ­¥éª¤ã€‚")

    print("\n[Done] æ‰€æœ‰ä»»åŠ¡å®Œæˆã€‚")
```