---
title: å›¾åƒåˆ†ç±»æ¨¡å‹é€šç”¨æ¨¡æ¿
date: 2026-01-12
tags:
  - Python
  - è®¡ç®—æœºè§†è§‰
  - å›¾åƒåˆ†ç±»
---

# å›¾åƒåˆ†ç±»æ¨¡å‹é€šç”¨æ¨¡æ¿

> æ‘˜è¦ï¼šä¸€ä¸ªå¯é…ç½®çš„ä»£ç æ¨¡æ¿ï¼Œç”¨äºè®­ç»ƒå›¾åƒåˆ†ç±»æ¨¡å‹

## æ ¸å¿ƒä»£ç ï¼š

```python
import os
import sys
import time
import random
import logging
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
from torchvision import datasets, transforms
import timm
from timm.data import resolve_data_config
from tqdm import tqdm
import matplotlib.pyplot as plt

# æ£€æŸ¥é«˜çº§ç»˜å›¾åº“
try:
    from sklearn.metrics import classification_report, confusion_matrix
    import seaborn as sns
    HAS_SKLEARN = True
except ImportError:
    HAS_SKLEARN = False
    print("[Warning] æœªå®‰è£… sklearn æˆ– seabornï¼Œè·³è¿‡æ··æ·†çŸ©é˜µç»˜åˆ¶ã€‚")

# ==========================================
# 1. å…¨å±€é…ç½® [æ ¸å¿ƒä¿®æ”¹åŒº]
# ==========================================
class Config:
    # --- æ•°æ®é›†è®¾ç½® ---
    USE_CUSTOM_DATASET = True        # <--- [å¯å¾®è°ƒ] True=è‡ªå®šä¹‰æ–‡ä»¶å¤¹, False=å†…ç½®
    CUSTOM_DATA_ROOT = "flower_data" # <--- [å¯å¾®è°ƒ] è‡ªå®šä¹‰æ•°æ®é›†è·¯å¾„
    BUILTIN_NAME = "CIFAR10"         # <--- [å¯å¾®è°ƒ] å†…ç½®æ•°æ®é›†åç§°
    DATA_DOWNLOAD_ROOT = "./data"    # <--- [å¯å¾®è°ƒ] ä¸‹è½½ç¼“å­˜è·¯å¾„
    
    # --- ç»“æœä¿å­˜ ---
    SAVE_DIR_ROOT = "./results"      # <--- [å¯å¾®è°ƒ] ç»“æœä¿å­˜æ ¹ç›®å½•
    SAVE_DIR = ""                    # (è¿è¡Œæ—¶è‡ªåŠ¨ç”Ÿæˆ)
    
    # --- æ¨¡å‹è®¾ç½® ---
    MODEL_NAME = "resnet50"          # <--- [å¯å¾®è°ƒ] æ¨¡å‹åç§° (timmåº“æ”¯æŒçš„åç§°)
    CHECKPOINT_PATH = ""             # <--- [å¯å¾®è°ƒ] åˆå§‹é¢„è®­ç»ƒæƒé‡ (è¿ç§»å­¦ä¹ ç”¨)
    RESUME_PATH = ""                 # <--- [å¯å¾®è°ƒ] æ–­ç‚¹ç»­è®­æ–‡ä»¶è·¯å¾„ (.pth)
    NUM_CLASSES = 0                  # (è¿è¡Œæ—¶è‡ªåŠ¨è¦†ç›–)
    
    # --- è®­ç»ƒè¶…å‚æ•° ---
    BATCH_SIZE = 32                  # <--- [å¯å¾®è°ƒ] æ‰¹æ¬¡å¤§å°
    EPOCHS = 50                      # <--- [å¯å¾®è°ƒ] è®­ç»ƒæ€»è½®æ•°
    LR = 1e-4                        # <--- [å¯å¾®è°ƒ] åˆå§‹å­¦ä¹ ç‡
    WEIGHT_DECAY = 1e-4              # <--- [å¯å¾®è°ƒ] L2æ­£åˆ™åŒ–ç³»æ•°
    SEED = 42                        # <--- [å¯å¾®è°ƒ] éšæœºç§å­
    
    # --- ç­–ç•¥é€‰æ‹© ---
    OPTIMIZER_NAME = 'adamw'         # <--- [å¯å¾®è°ƒ] 'adamw', 'adam', 'sgd'
    SCHEDULER_NAME = 'plateau'       # <--- [å¯å¾®è°ƒ] 'plateau', 'cosine', 'step'
    EARLY_STOP_PATIENCE = 7          # <--- [å¯å¾®è°ƒ] æ—©åœè€å¿ƒè½®æ•° (0=å…³é—­)
    
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ==========================================
# 2. è¾…åŠ©å·¥å…·
# ==========================================
def setup_logger(save_dir):
    """é…ç½®æ—¥å¿—ï¼šåŒæ—¶è¾“å‡ºåˆ°æ–‡ä»¶å’Œæ§åˆ¶å°"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(message)s',
        handlers=[
            logging.FileHandler(os.path.join(save_dir, "train.log")),
            logging.StreamHandler(sys.stdout)
        ]
    )
    return logging.getLogger()

def seed_everything(seed):
    """å›ºå®šéšæœºç§å­"""
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True

class EarlyStopping:
    """æ—©åœæ§åˆ¶å™¨"""
    def __init__(self, patience=7, delta=0):
        self.patience = patience
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.delta = delta

    def __call__(self, val_acc):
        if self.patience <= 0: return
        if self.best_score is None:
            self.best_score = val_acc
        elif val_acc < self.best_score + self.delta:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = val_acc
            self.counter = 0

def get_optimizer(model):
    """ä¼˜åŒ–å™¨å·¥å‚"""
    name = Config.OPTIMIZER_NAME.lower()
    p = model.parameters()
    if name == 'adamw': return optim.AdamW(p, lr=Config.LR, weight_decay=Config.WEIGHT_DECAY)
    elif name == 'sgd': return optim.SGD(p, lr=Config.LR, momentum=0.9, weight_decay=Config.WEIGHT_DECAY)
    else: return optim.Adam(p, lr=Config.LR, weight_decay=Config.WEIGHT_DECAY)

def get_scheduler(optimizer):
    """å­¦ä¹ ç‡ç­–ç•¥å·¥å‚"""
    name = Config.SCHEDULER_NAME.lower()
    if name == 'plateau': return optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)
    elif name == 'cosine': return optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=Config.EPOCHS, eta_min=1e-6)
    elif name == 'step': return optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)
    return None

# ==========================================
# 3. æ•°æ®åŠ è½½ä¸å¤„ç†
# ==========================================
def get_transforms(model_cfg):
    """æ ¹æ®æ¨¡å‹é…ç½®ç”ŸæˆTransforms"""
    input_size = model_cfg.get('input_size', (3, 224, 224))
    crop_size = input_size[1]
    mean = model_cfg.get('mean', [0.485, 0.456, 0.406])
    std = model_cfg.get('std', [0.229, 0.224, 0.225])
    
    train_tf = transforms.Compose([
        transforms.Resize((crop_size, crop_size)),
        transforms.RandomHorizontalFlip(0.5),
        transforms.RandomRotation(15),
        transforms.ColorJitter(0.1, 0.1, 0.1),
        transforms.ToTensor(),
        transforms.Normalize(mean, std)
    ])
    val_tf = transforms.Compose([
        transforms.Resize((crop_size, crop_size)),
        transforms.ToTensor(),
        transforms.Normalize(mean, std)
    ])
    return train_tf, val_tf

def get_dataloaders(train_tf, val_tf, logger):
    """åŠ è½½æ•°æ®é›†"""
    if not Config.USE_CUSTOM_DATASET:
        logger.info(f"[Data] åŠ è½½å†…ç½®æ•°æ®é›†: {Config.BUILTIN_NAME}")
        try: DatasetClass = getattr(datasets, Config.BUILTIN_NAME)
        except AttributeError: raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®é›†: {Config.BUILTIN_NAME}")
        
        full_ds = DatasetClass(root=Config.DATA_DOWNLOAD_ROOT, train=True, download=True, transform=train_tf)
        test_ds = DatasetClass(root=Config.DATA_DOWNLOAD_ROOT, train=False, download=True, transform=val_tf)
        
        train_sz = int(0.9 * len(full_ds))
        train_ds, val_ds = random_split(full_ds, [train_sz, len(full_ds)-train_sz])
        class_names = full_ds.classes
        ds_name = Config.BUILTIN_NAME
    else:
        logger.info(f"[Data] åŠ è½½è‡ªå®šä¹‰æ–‡ä»¶å¤¹: {Config.CUSTOM_DATA_ROOT}")
        train_dir = os.path.join(Config.CUSTOM_DATA_ROOT, "train")
        val_dir = os.path.join(Config.CUSTOM_DATA_ROOT, "val")
        test_dir = os.path.join(Config.CUSTOM_DATA_ROOT, "test")
        
        if not os.path.exists(train_dir): raise FileNotFoundError(f"ç¼ºå¤±ç›®å½•: {train_dir}")
        train_ds = datasets.ImageFolder(train_dir, transform=train_tf)
        val_ds = datasets.ImageFolder(val_dir, transform=val_tf)
        test_ds = datasets.ImageFolder(test_dir, transform=val_tf) if os.path.exists(test_dir) else None
        class_names = train_ds.classes
        ds_name = os.path.basename(Config.CUSTOM_DATA_ROOT)

    Config.NUM_CLASSES = len(class_names)
    logger.info(f"[Data] ç±»åˆ«æ•°: {Config.NUM_CLASSES}")
    
    train_dl = DataLoader(train_ds, batch_size=Config.BATCH_SIZE, shuffle=True, num_workers=4)
    val_dl = DataLoader(val_ds, batch_size=Config.BATCH_SIZE, shuffle=False, num_workers=4)
    test_dl = DataLoader(test_ds, batch_size=Config.BATCH_SIZE, shuffle=False, num_workers=4) if test_ds else None
    
    return train_dl, val_dl, test_dl, class_names, ds_name

# ==========================================
# 4. è®­ç»ƒä¸éªŒè¯æ ¸å¿ƒ
# ==========================================
def train_one_epoch(model, loader, criterion, optimizer, epoch):
    model.train()
    total_loss, total_correct = 0.0, 0
    bar = tqdm(loader, desc=f"Epoch {epoch}/{Config.EPOCHS} [Train]", leave=False)
    
    for imgs, labels in bar:
        imgs, labels = imgs.to(Config.DEVICE), labels.to(Config.DEVICE)
        
        optimizer.zero_grad()
        outputs = model(imgs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item() * imgs.size(0)
        total_correct += (outputs.argmax(1) == labels).sum().item()
        bar.set_postfix(loss=loss.item(), lr=optimizer.param_groups[0]['lr'])
        
    return total_loss / len(loader.dataset), total_correct / len(loader.dataset)

@torch.no_grad()
def validate(model, loader, criterion, epoch, phase="Val"):
    model.eval()
    total_loss, total_correct = 0.0, 0
    bar = tqdm(loader, desc=f"Epoch {epoch}/{Config.EPOCHS} [{phase}]  ", leave=False)
    
    for imgs, labels in bar:
        imgs, labels = imgs.to(Config.DEVICE), labels.to(Config.DEVICE)
        outputs = model(imgs)
        loss = criterion(outputs, labels)
            
        total_loss += loss.item() * imgs.size(0)
        total_correct += (outputs.argmax(1) == labels).sum().item()
        bar.set_postfix(loss=loss.item())
        
    return total_loss / len(loader.dataset), total_correct / len(loader.dataset)

def evaluate_test_set(model, loader, class_names, logger):
    """æµ‹è¯•é›†è¯„ä¼°ä¸æ··æ·†çŸ©é˜µç»˜åˆ¶"""
    if not loader or not HAS_SKLEARN: return
    logger.info("[Test] æ‰§è¡Œæœ€ç»ˆè¯„ä¼°...")
    model.eval()
    preds, targets = [], []
    
    with torch.no_grad():
        for imgs, labels in tqdm(loader, desc="Testing"):
            imgs, labels = imgs.to(Config.DEVICE), labels.to(Config.DEVICE)
            outputs = model(imgs)
            preds.extend(outputs.argmax(1).cpu().numpy())
            targets.extend(labels.cpu().numpy())
    
    report = classification_report(targets, preds, target_names=class_names, digits=4)
    logger.info("\n" + report)
    print(report)
    
    plt.figure(figsize=(10, 8))
    sns.heatmap(confusion_matrix(targets, preds), annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
    plt.title('Confusion Matrix'); plt.savefig(os.path.join(Config.SAVE_DIR, 'confusion_matrix.png'))
    logger.info("[Info] æ··æ·†çŸ©é˜µå·²ä¿å­˜")

def plot_history(h, save_dir, logger):
    epochs = range(1, len(h['train_acc']) + 1)
    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1); plt.plot(epochs, h['train_acc'], label='Train'); plt.plot(epochs, h['val_acc'], label='Val'); plt.legend(); plt.title('Accuracy')
    plt.subplot(1, 2, 2); plt.plot(epochs, h['train_loss'], label='Train'); plt.plot(epochs, h['val_loss'], label='Val'); plt.legend(); plt.title('Loss')
    plt.savefig(os.path.join(save_dir, 'training_curve.png'))
    logger.info("[Info] è®­ç»ƒæ›²çº¿å·²ä¿å­˜")

def save_checkpoint(state, is_best, filename='last.pth'):
    path = os.path.join(Config.SAVE_DIR, filename)
    torch.save(state, path)
    if is_best: torch.save(state, os.path.join(Config.SAVE_DIR, 'best_model.pth'))

# ==========================================
# 5. ä¸»ç¨‹åº
# ==========================================
if __name__ == "__main__":
    seed_everything(Config.SEED)
    
    # 1. ç¡®å®šä¿å­˜ç›®å½•
    if Config.RESUME_PATH:
        # æ–­ç‚¹ç»­è®­å¤ç”¨åŸç›®å½•
        Config.SAVE_DIR = os.path.dirname(Config.RESUME_PATH)
    else:
        # è·å–æ•°æ®é›†åç§°ç”¨äºå‘½å
        if Config.USE_CUSTOM_DATASET:
            ds_name = os.path.basename(Config.CUSTOM_DATA_ROOT)
        else:
            ds_name = Config.BUILTIN_NAME
            
        # æ ¼å¼: æ¨¡å‹å_æ•°æ®é›†å_æ—¶é—´æˆ³
        run_name = f"{Config.MODEL_NAME}_{ds_name}_{time.strftime('%Y%m%d_%H%M%S')}"
        Config.SAVE_DIR = os.path.join(Config.SAVE_DIR_ROOT, run_name)
        os.makedirs(Config.SAVE_DIR, exist_ok=True)
    
    logger = setup_logger(Config.SAVE_DIR)
    logger.info(f"[Config] ä¿å­˜ç›®å½•: {Config.SAVE_DIR}")
    
    # 2. å‡†å¤‡æ•°æ®
    tmp_model = timm.create_model(Config.MODEL_NAME, pretrained=True)
    cfg = resolve_data_config({}, model=tmp_model)
    del tmp_model
    
    train_tf, val_tf = get_transforms(cfg)
    train_dl, val_dl, test_dl, class_names, ds_name = get_dataloaders(train_tf, val_tf, logger)
    
    # 3. åˆå§‹åŒ–æ¨¡å‹
    logger.info(f"[Init] åˆ›å»ºæ¨¡å‹: {Config.MODEL_NAME}")
    if not Config.RESUME_PATH and Config.CHECKPOINT_PATH and os.path.exists(Config.CHECKPOINT_PATH):
        logger.info(f"[Load] åŠ è½½æœ¬åœ°åˆå§‹åŒ–æƒé‡: {Config.CHECKPOINT_PATH}")
        model = timm.create_model(Config.MODEL_NAME, pretrained=False, checkpoint_path=Config.CHECKPOINT_PATH)
    else:
        model = timm.create_model(Config.MODEL_NAME, pretrained=True)
        
    model.reset_classifier(num_classes=Config.NUM_CLASSES)
    model.to(Config.DEVICE)
    
    # 4. ä¼˜åŒ–å™¨/è°ƒåº¦å™¨/Loss
    optimizer = get_optimizer(model)
    scheduler = get_scheduler(optimizer)
    criterion = nn.CrossEntropyLoss()
    early_stop = EarlyStopping(patience=Config.EARLY_STOP_PATIENCE) if Config.EARLY_STOP_PATIENCE > 0 else None
    
    # 5. æ–­ç‚¹æ¢å¤é€»è¾‘
    start_epoch = 1
    best_acc = 0.0
    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}
    
    if Config.RESUME_PATH and os.path.exists(Config.RESUME_PATH):
        logger.info(f"[Resume] æ¢å¤æ–­ç‚¹: {Config.RESUME_PATH}")
        ckpt = torch.load(Config.RESUME_PATH, map_location=Config.DEVICE)
        model.load_state_dict(ckpt['state_dict'])
        optimizer.load_state_dict(ckpt['optimizer'])
        if scheduler and 'scheduler' in ckpt: scheduler.load_state_dict(ckpt['scheduler'])
        
        start_epoch = ckpt['epoch'] + 1
        best_acc = ckpt['best_acc']
        history = ckpt['history']
        logger.info(f"[Resume] ä»ç¬¬ {start_epoch} è½®ç»§ç»­ (æœ€ä½³Acc: {best_acc:.4f})")
    
    # 6. è®­ç»ƒå¾ªç¯
    logger.info("[Start] å¼€å§‹è®­ç»ƒ...")
    for epoch in range(start_epoch, Config.EPOCHS + 1):
        t_loss, t_acc = train_one_epoch(model, train_dl, criterion, optimizer, epoch)
        v_loss, v_acc = validate(model, val_dl, criterion, epoch)
        
        history['train_loss'].append(t_loss); history['train_acc'].append(t_acc)
        history['val_loss'].append(v_loss); history['val_acc'].append(v_acc)
        
        logger.info(f"Epoch {epoch}: Train Acc: {t_acc:.4f} | Val Acc: {v_acc:.4f} | Loss: {t_loss:.4f}")
        
        # å­¦ä¹ ç‡æ›´æ–°
        if scheduler:
            if Config.SCHEDULER_NAME == 'plateau': scheduler.step(v_acc)
            else: scheduler.step()
            
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        is_best = v_acc > best_acc
        if is_best:
            best_acc = v_acc
            logger.info(f" -> ğŸŒŸ æ–°çš„æœ€ä½³æ¨¡å‹ (Acc: {best_acc:.4f})")
            
        # ä¿å­˜æ–­ç‚¹
        save_checkpoint({
            'epoch': epoch,
            'state_dict': model.state_dict(),
            'best_acc': best_acc,
            'optimizer': optimizer.state_dict(),
            'scheduler': scheduler.state_dict() if scheduler else None,
            'history': history
        }, is_best)
        
        # æ—©åœæ£€æµ‹
        if early_stop:
            early_stop(v_acc)
            if early_stop.early_stop:
                logger.info("[Stop] è§¦å‘æ—©åœ")
                break
                
    # 7. æ”¶å°¾
    plot_history(history, Config.SAVE_DIR, logger)
    if test_dl:
        ckpt = torch.load(os.path.join(Config.SAVE_DIR, "best_model.pth"), map_location=Config.DEVICE)
        model.load_state_dict(ckpt['state_dict'])
        evaluate_test_set(model, test_dl, class_names, logger)
        
    logger.info("[Done] å®Œæˆ")
```